Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/wsj_small.dparser.vw.gz.cache
Reading datafile = train-sets/wsj_small.dparser.vw.gz
num sources = 1
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
42.000000  42.000000         1  [43 5 5 5 1 5 9 9 6..] [0 1 2 3 4 5 6 7 8 ..]     0     0       96        0       96  0.009455
23.500000  5.000000          2  [2 3 0 3 3           ] [0 1 1 1 1           ]     0     0      104        0      104  0.010248
18.000000  12.500000         4  [4 4 4 7 6 7 0 9 7 ..] [2 0 2 2 4 2 2 7 2 ..]     0     0      164        0      164  0.016169
13.750000  9.500000          8  [3 3 4 0 4 4 6 4     ] [3 3 0 3 3 3 6 3     ]     0     0      279        0      278  0.027321
15.375000  17.000000        16  [5 5 4 5 0 5 5 5 8 ..] [0 4 4 5 1 5 5 5 8 ..]     0     0      753        0      730  0.070310
14.187500  13.000000        32  [2 3 0 3 6 4 8 4 11..] [2 3 0 3 4 7 4 4 11..]     0     0     1708        0     1580  0.146072
12.375000  10.562500        64  [16 16 4 16 6 4 6 9..] [41 1 1 3 6 4 6 9 7..]     0     0     3781        0     3266  0.278567
7.875000   3.375000        128  [3 3 0 3 7 7 11 11 ..] [3 3 0 3 7 7 11 11 ..]     1     0     8391        0     6606  0.483424

finished run
number of examples per pass = 71
passes used = 2
weighted example sum = 142
weighted label sum = 0
average loss = 7.43662
total feature number = 1719480
