Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/0001.dat.cache
Reading datafile = train-sets/0001.dat
num sources = 1
Enabled reductions: gd, scorer-identity
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000       51
0.513618 0.027236            2            2.0   0.0000   0.1650      104
0.263121 0.012624            4            4.0   0.0000   0.0569      135
0.237739 0.212356            8            8.0   0.0000   0.2024      146
0.248570 0.259401           16           16.0   1.0000   0.2048      143
0.230779 0.212988           32           32.0   1.0000   0.4685       70
0.232955 0.235132           64           64.0   0.0000   0.4225       34
0.219769 0.206582          128          128.0   0.0000   0.1011       30
0.164100 0.164100          256          256.0   0.0000   0.1326       72 h

finished run
number of examples per pass = 180
passes used = 2
weighted example sum = 360.000000
weighted label sum = 160.000000
average loss = 0.153098 h
best constant = 0.444444
best constant's loss = 0.246914
total feature number = 27566
