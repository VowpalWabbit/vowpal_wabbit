Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/cb_multi_cost.dat.cache
Reading datafile = train-sets/cb_multi_cost.dat
num sources = 1
Enabled reductions: gd, scorer, csoaa_ldf, cb_adf, shared_feature_merger, cb_to_cbadf
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0    0:1:1        0:0...       16
1.500000 2.000000            2            2.0    1:2:1        1:0...       16
2.500000 3.500000            4            4.0    3:4:1        3:0...       16
1.750000 1.000000            8            8.0    2:3:1        2:0.460451...       16

finished run
number of examples per pass = 5
passes used = 2
weighted example sum = 10.000000
weighted label sum = 0.000000
average loss = 1.800000
total feature number = 160
