using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled reductions: gd, scorer-identity, count_label
Input label = simple
Output pred = scalar
average  since         example        example        current        current  current 
loss     last          counter         weight          label        predict features 
0.251936 0.251936           10           10.0         1.0000         0.2253       34 
0.235270 0.218604           20           20.0         0.0000         0.2122      104 
0.240929 0.252245           30           30.0         0.0000         0.3390       82 
0.229257 0.194240           40           40.0         1.0000         0.5489       42 
0.225418 0.210064           50           50.0         0.0000         0.2070       60 
0.232321 0.266835           60           60.0         0.0000         0.3381      147 
0.229974 0.215889           70           70.0         1.0000         0.4733      134 
0.226343 0.200933           80           80.0         0.0000         0.2217      136 
0.217408 0.145922           90           90.0         0.0000         0.2602      139 
0.216702 0.210354          100          100.0         1.0000         0.3171       56 
0.218355 0.234885          110          110.0         1.0000         0.5796       97 
0.226823 0.319971          120          120.0         0.0000         0.4138      120 
0.223090 0.178297          130          130.0         1.0000         0.4105       54 
0.218306 0.156105          140          140.0         0.0000         0.3486       82 
0.212760 0.135113          150          150.0         1.0000         0.4022      148 
0.211695 0.195721          160          160.0         0.0000         0.6071       63 
0.206602 0.125119          170          170.0         1.0000         0.7091       69 
0.202213 0.127599          180          180.0         1.0000         0.7582       42 
0.198752 0.136457          190          190.0         1.0000         0.7647       34 
0.195759 0.138893          200          200.0         1.0000         0.5243       56 

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.195759
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
