predictions = classic_loss.predict
using no cache
Reading datafile = train-sets/0002_25.dat
num sources = 1
Num weight bits = 7
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled learners: gd, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.271591 0.271591            1            1.0         0.5211         0.0000       15
0.135795 0.000000            2            2.0         0.5353         0.5353       15
0.068204 0.000613            4            4.0         0.5854         0.5854       15
0.046512 0.024820            8            8.0         0.5575         0.6863       15
0.069917 0.093321           16           16.0         0.5878         0.6481       15

finished run
number of examples = 25
weighted example sum = 25.000000
weighted label sum = 12.754523
average loss = 0.048876
best constant = 0.510181
total feature number = 374
