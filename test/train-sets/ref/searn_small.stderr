Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/seq_small.cache
Reading from train-sets/seq_small
num sources = 1
average    since       example  example    current  current  current
loss       last        counter   weight      label  predict features
#pol  average    since      sequence         example            current label      current predicted  current   cur   cur         predic.        examples
chng  loss       last        counter          weight          sequence prefix        sequence prefix features  pass   pol            made          gener.
   0  1.333333   1.333333          3        3.000000   [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]       18     2     0              18              12
   1  1.000000   0.666667          6        6.000000   [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]       18     5     1              49              30
   1  0.727273   0.400000         11       11.000000   [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]       18    10     2             162              60

finished run
number of examples = 12
weighted example sum = 12
weighted label sum = 0
average loss = 0.6667
best constant = -0.09091
total feature number = 552
