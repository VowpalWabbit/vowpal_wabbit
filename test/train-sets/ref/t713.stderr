creating cache_file = train-sets/0002.dat.cache
Reading datafile = train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
Enabled learners: gd, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.271591 0.271591            1            1.0         0.5211         0.0000       15
0.136120 0.000650            2            2.0         0.5353         0.5098       15
0.070811 0.005501            4            4.0         0.5933         0.5810       15
0.066908 0.063006            8            8.0         0.4315         0.0000       15
0.076303 0.085699           16           16.0         0.5836         0.4863       15
0.045874 0.015445           32           32.0         0.5503         0.4229       15
0.030087 0.014301           64           64.0         0.3614         0.2027       15
0.017438 0.004788          128          128.0         0.5445         0.5392       15
0.010553 0.003667          256          256.0         0.4930         0.5753       15
0.006213 0.001874          512          512.0         0.5147         0.4592       15
0.002870 0.002870         1024         1024.0         0.6139         0.5974       15 h
0.001579 0.000287         2048         2048.0         0.5026         0.4988       15 h

finished run
number of examples per pass = 667
passes used = 5
weighted example sum = 3335.000000
weighted label sum = 1751.936305
average loss = 0.000289 h
best constant = 0.525318
total feature number = 50010
