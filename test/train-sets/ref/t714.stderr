creating cache_file = train-sets/0002.dat.cache
Reading datafile = train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
Enabled learners: gd, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.271591 0.271591            1            1.0         0.5211         0.0000       15
0.136120 0.000650            2            2.0         0.5353         0.5098       15
0.109867 0.083614            4            4.0         0.5854         0.5854       15
0.075648 0.041428            8            8.0         0.5575         0.4495       15
0.082329 0.089010           16           16.0         0.5000         0.2937       14
0.045790 0.009250           32           32.0         0.5253         0.5314       15
0.028557 0.011324           64           64.0         0.5825         0.5889       15
0.017338 0.006119          128          128.0         0.5763         0.5720       15
0.010403 0.003467          256          256.0         0.5941         0.5349       15
0.006299 0.002195          512          512.0         0.2477         0.3751       15
0.002043 0.002043         1024         1024.0         0.5166         0.4808       15 h
0.001172 0.000308         2048         2048.0         0.5546         0.5531       15 h
0.000669 0.000168         4096         4096.0         0.5083         0.5129       15 h
0.000405 0.000142         8192         8192.0         0.5366         0.5267       15 h

finished run
number of examples per pass = 900
passes used = 10
weighted example sum = 9000.000000
weighted label sum = 4733.412646
average loss = 0.000130 h
best constant = 0.525935
total feature number = 134960
