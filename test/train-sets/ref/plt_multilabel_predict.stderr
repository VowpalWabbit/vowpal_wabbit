only testing
predictions = plt_multilabel.predict
PLT k = 10
kary_tree = 2
threshold = 0.5
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/multilabel
num sources = 1
Enabled reductions: gd, scorer-identity, plt
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0      0 1      0 1        2
1.500000 3.000000            2            2.0      1 2    2 1 8        2
2.000000 2.500000            4            4.0      3 4        8        2
2.250000 2.500000            8            8.0        8      1 8        2

finished run
number of examples = 10
weighted example sum = 10.000000
weighted label sum = 0.000000
average loss = 1.900000
total feature number = 20
hamming loss = 1.700000
precision = 0.562500
recall = 0.473684
