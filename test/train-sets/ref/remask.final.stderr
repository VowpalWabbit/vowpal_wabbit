using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled reductions: gd, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.000002 0.000002            1            1.0         1.0000         0.9986       51
0.199287 0.398572            2            2.0         0.0000         0.6313      104
0.099644 0.000000            4            4.0         0.0000         0.0000      135
0.094847 0.090051            8            8.0         0.0000         0.0000      146
0.077409 0.059972           16           16.0         1.0000         0.7652       24
0.073032 0.068654           32           32.0         0.0000         0.0857       32
0.091694 0.110356           64           64.0         0.0000         0.0000       61
0.092357 0.093019          128          128.0         1.0000         1.0000      106

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.080263
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
