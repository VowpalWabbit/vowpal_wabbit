creating cubic features for triples: abc 
final_regressor = models/xxor.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/xxor.dat.cache
Reading datafile = train-sets/xxor.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000        5
0.581525   0.163049            2         2.0   0.0000   0.4038        5
0.422704   0.105064            3         3.0   0.0000   0.3241        5
0.567028   1.000000            4         4.0   1.0000   0.0000        5
0.527970   0.449852            6         6.0   1.0000   0.1235        5
0.493858   0.391523            8         8.0   0.0000   0.6019        5
0.407022   0.175458           11        11.0   0.0000   0.4429        5
0.361109   0.234848           15        15.0   1.0000   0.5645        5
0.304274   0.133770           20        20.0   1.0000   0.5956        5
0.249203   0.091857           27        27.0   0.0000   0.2644        5
0.201723   0.059283           36        36.0   1.0000   0.7710        5
0.158986   0.030775           48        48.0   0.0000   0.1478        5
0.122699   0.013839           64        64.0   0.0000   0.0883        5
0.092576   0.004943           86        86.0   1.0000   0.9496        5
0.069532   0.001197          115       115.0   0.0000   0.0223        5
0.051971   0.000188          154       154.0   0.0000   0.0084        5
0.038856   0.000016          206       206.0   1.0000   0.9988        5
0.029107   0.000001          275       275.0   0.0000   0.0002        5
0.021811   0.000000          367       367.0   1.0000   1.0000        5
0.016336   0.000000          490       490.0   0.0000   0.0000        5
0.012239   0.000000          654       654.0   1.0000   1.0000        5

finished run
number of examples per pass = 8
passes used = 100
weighted example sum = 800
weighted label sum = 400
average loss = 0.0100056
best constant = 0.5
best constant's loss = 0.25
total feature number = 4000
