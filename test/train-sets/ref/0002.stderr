final_regressor = models/0002.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.110373   0.110373            3         3.0   0.5498   0.3594       15
0.070583   0.030793            6         6.0   0.2681   0.0000       15
0.064438   0.057063           11        11.0   0.4315   0.0000       15
0.039229   0.014019           22        22.0   0.5519   0.5517       15
0.021604   0.003980           44        44.0   0.5514   0.6262       15
0.013920   0.006057           87        87.0   0.5140   0.5201       15
0.009675   0.005429          174       174.0   0.5596   0.5380       15
0.006822   0.003970          348       348.0   0.5475   0.5607       15
0.004424   0.002025          696       696.0   0.3421   0.3962       15
0.002822   0.001220         1392      1392.0   0.4996   0.4954       15
0.001751   0.000680         2784      2784.0   0.5090   0.5309       15
0.001175   0.000600         5568      5568.0   0.6413   0.6318       15
0.000994   0.000812        11135     11135.0   0.3869   0.4411       15
0.000893   0.000792        22269     22269.0   0.5063   0.5156       15
0.001101   0.001310        44537     44537.0   0.4905   0.4683       15

finished run
number of examples = 74746
weighted example sum = 6.952e+04
weighted label sum = 3.511e+04
average loss = 0.001248
best constant = 0.5051
best constant's loss = 0.25
total feature number = 1119986
