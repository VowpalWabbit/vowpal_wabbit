final_regressor = models/0002.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
Enabled reductions: gd, scorer-identity
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.271591 0.271591            1            1.0   0.5211   0.0000       15
0.147424 0.023257            2            2.0   0.5353   0.3827       15
0.082780 0.018136            4            4.0   0.5854   0.5854       15
0.054549 0.026318            8            8.0   0.5575   0.6541       15
0.047005 0.039460           16           16.0   0.5878   0.5414       15
0.025775 0.004545           32           32.0   0.6038   0.6160       15
0.014549 0.003323           64           64.0   0.5683   0.5105       15
0.010060 0.005570          128          128.0   0.5351   0.5202       15
0.007204 0.004349          256          256.0   0.5385   0.5453       15
0.005157 0.003109          512          512.0   0.5053   0.5507       15

finished run
number of examples = 1000
weighted example sum = 1000.000000
weighted label sum = 526.517528
average loss = 0.003382
best constant = 0.526518
total feature number = 14996
