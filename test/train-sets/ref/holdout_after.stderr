Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
Enabled reductions: gd, scorer-identity
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.020368 0.020368          100          100.0   0.5266   0.5147       15
0.012680 0.004993          200          200.0   0.4325   0.4097       15
0.009549 0.003287          300          300.0   0.5299   0.5367       15
0.007654 0.001969          400          400.0   0.4884   0.4973       15
0.006393 0.001347          500          500.0   0.5113   0.5266       15

finished run
number of examples = 500
weighted example sum = 500.000000
weighted label sum = 261.609450
average loss = 0.003059 h
best constant = 0.523219
total feature number = 7497
