Driver Options:
  --onethread                         Disable parse thread
  --log_level arg (=info, )           Log level for logging messages.
                                      Specifying this wil override --quiet for
                                      log output.. Choices: {critical, error,
                                      info, off, warn}
  --log_output_stream arg (=compat, ) Specify the stream to output log messages
                                      to. In the past VW's choice of stream for
                                      logging messages wasn't consistent.
                                      Suppling compat will maintain that old
                                      behavior. Compat is now deprecated so it
                                      is recommended that stdout or stderr is
                                      chosen.. Choices: {compat, stderr,
                                      stdout}
Logging options Options:
  --quiet                               Don't output diagnostics and progress
                                        updates. Supplying this implies
                                        --log_level off and --driver_output_off
                                        .
  --driver_output_off                   Disable output for the driver.
  --driver_output_stream arg (=stderr, )
                                        Specify the stream to output driver
                                        output to.. Choices: {stderr, stdout}
  --log_level arg (=info, )             Log level for logging messages.
                                        Specifying this wil override --quiet
                                        for log output.. Choices: {critical,
                                        error, info, off, warn}
  --log_output_stream arg (=compat, )   Specify the stream to output log
                                        messages to. In the past VW's choice of
                                        stream for logging messages wasn't
                                        consistent. Suppling compat will
                                        maintain that old behavior. Compat is
                                        now deprecated so it is recommended
                                        that stdout or stderr is chosen..
                                        Choices: {compat, stderr, stdout}
VW Options:
  --ring_size arg (=256, ) Size of example ring
  --strict_parse           Throw on malformed examples
Update Options:
  -l [ --learning_rate ] arg Set learning rate
  --power_t arg              T power value
  --decay_learning_rate arg  Set Decay factor for learning_rate between passes
  --initial_t arg            Initial t value
  --feature_mask arg         Use existing regressor to determine which
                             parameters may be updated.  If no
                             initial_regressor given, also used for initial
                             weights.
Weight Options:
  -i [ --initial_regressor ] arg  Initial regressor(s)
  --initial_weight arg            Set all weights to an initial value of arg
  --random_weights                Make initial weights random
  --normal_weights                Make initial weights normal
  --truncated_normal_weights      Make initial weights truncated normal
  --sparse_weights                Use a sparse datastructure for weights
  --input_feature_regularizer arg Per feature regularization input file
Parallelization Options:
  --span_server arg                 Location of server for setting up spanning
                                    tree
  --unique_id arg (=0, )            Unique id used for cluster parallel jobs
  --total arg (=1, )                Total number of nodes used in cluster
                                    parallel job
  --node arg (=0, )                 Node number in cluster parallel job
  --span_server_port arg (=26543, ) Port of the server for setting up spanning
                                    tree
Diagnostic Options:
  --version             Version information
  -a [ --audit ]        Print weights of features
  -P [ --progress ] arg Progress update frequency. int: additive, float:
                        multiplicative
  --limit_output arg    Avoid chatty output. Limit total printed lines
  --dry_run             Parse arguments and print corresponding metadata. Will
                        not execute driver
  -h [ --help ]         More information on vowpal wabbit can be found here
                        https://vowpalwabbit.org
Randomization Options:
  --random_seed arg     Seed random number generator
Feature Options:
  --hash arg                            How to hash the features. Choices:
                                        {all, strings}
  --hash_seed arg (=0, )                Seed for hash function
  --ignore arg                          Ignore namespaces beginning with
                                        character <arg>
  --ignore_linear arg                   Ignore namespaces beginning with
                                        character <arg> for linear terms only
  --keep arg                            Keep namespaces beginning with
                                        character <arg>
  --redefine arg                        Redefine namespaces beginning with
                                        characters of std::string S as
                                        namespace N. <arg> shall be in form
                                        'N:=S' where := is operator. Empty N or
                                        S are treated as default namespace. Use
                                        ':' as a wildcard in S.
  -b [ --bit_precision ] arg            Number of bits in the feature table
  --noconstant                          Don't add a constant feature
  -C [ --constant ] arg                 Set initial value of constant
  --ngram arg                           Generate N grams. To generate N grams
                                        for a single namespace 'foo', arg
                                        should be fN
  --skips arg                           Generate skips in N grams. This in
                                        conjunction with the ngram tag can be
                                        used to generate generalized
                                        n-skip-k-gram. To generate n-skips for
                                        a single namespace 'foo', arg should be
                                        fN.
  --feature_limit arg                   Limit to N unique features per
                                        namespace. To apply to a single
                                        namespace 'foo', arg should be fN
  --affix arg                           Generate prefixes/suffixes of features;
                                        argument '+2a,-3b,+1' means generate
                                        2-char prefixes for namespace a, 3-char
                                        suffixes for b and 1 char prefixes for
                                        default namespace
  --spelling arg                        Compute spelling features for a give
                                        namespace (use '_' for default
                                        namespace)
  --dictionary arg                      Read a dictionary for additional
                                        features (arg either 'x:file' or just
                                        'file')
  --dictionary_path arg                 Look in this directory for
                                        dictionaries; defaults to current
                                        directory or env{PATH}
  --interactions arg                    Create feature interactions of any
                                        level between namespaces
  --experimental_full_name_interactions arg
                                        EXPERIMENTAL: Create feature
                                        interactions of any level between
                                        namespaces by specifying the full name
                                        of each namespace.
  --permutations                        Use permutations instead of
                                        combinations for feature interactions
                                        of same namespace
  --leave_duplicate_interactions        Don't remove interactions with
                                        duplicate combinations of namespaces.
                                        For ex. this is a duplicate: '-q ab -q
                                        ba' and a lot more in '-q ::'.
  -q [ --quadratic ] arg                Create and use quadratic features
  --q: arg                              DEPRECATED ':' corresponds to a
                                        wildcard for all printable characters
  --cubic arg                           Create and use cubic features
Example Options:
  -t [ --testonly ]                Ignore label information and just test
  --holdout_off                    No holdout data in multiple passes
  --holdout_period arg (=10, )     Holdout period for test only
  --holdout_after arg              Holdout after n training examples, default
                                   off (disables holdout_period)
  --early_terminate arg (=3, )     Specify the number of passes tolerated when
                                   holdout loss doesn't decrease before early
                                   termination
  --passes arg                     Number of Training Passes
  --initial_pass_length arg        Initial number of examples per pass
  --examples arg                   Number of examples to parse
  --min_prediction arg             Smallest prediction to output
  --max_prediction arg             Largest prediction to output
  --sort_features                  Turn this on to disregard order in which
                                   features have been defined. This will lead
                                   to smaller cache sizes
  --loss_function arg (=squared, ) Specify the loss function to be used, uses
                                   squared by default. Choices: {classic,
                                   hinge, logistic, poisson, quantile, squared}
  --quantile_tau arg (=0.5, )      Parameter \tau associated with Quantile
                                   loss. Defaults to 0.5
  --l1 arg                         L_1 lambda
  --l2 arg                         L_2 lambda
  --no_bias_regularization         No bias in regularization
  --named_labels arg               Use names for labels (multiclass, etc.)
                                   rather than integers, argument specified all
                                   possible labels, comma-sep, eg
                                   "--named_labels Noun,Verb,Adj,Punc"
Output Model Options:
  -f [ --final_regressor ] arg          Final regressor
  --readable_model arg                  Output human-readable final regressor
                                        with numeric features
  --invert_hash arg                     Output human-readable final regressor
                                        with feature names.  Computationally
                                        expensive
  --predict_only_model                  Do not save extra state for learning to
                                        be resumed. Stored model can only be
                                        used for prediction
  --save_resume                         This flag is now deprecated and models
                                        can continue learning by default
  --preserve_performance_counters       Reset performance counters when
                                        warmstarting
  --save_per_pass                       Save the model after every pass over
                                        data
  --output_feature_regularizer_binary arg
                                        Per feature regularization output file
  --output_feature_regularizer_text arg Per feature regularization output file,
                                        in text
  --id arg                              User supplied ID embedded into the
                                        final regressor
Output Options:
  -p [ --predictions ] arg     File to output predictions to
  -r [ --raw_predictions ] arg File to output unnormalized predictions to
Input Options:
  -d [ --data ] arg     Example set
  --daemon              Persistent daemon mode on port 26542
  --foreground          In persistent daemon mode, do not run in the background
  --port arg            Port to listen on; use 0 to pick unused port
  --num_children arg    Number of children for persistent daemon mode
  --pid_file arg        Write pid file in persistent daemon mode
  --port_file arg       Write port used in persistent daemon mode
  -c [ --cache ]        Use a cache.  The default is <data>.cache
  --cache_file arg      The location(s) of cache_file
  --json                Enable JSON parsing
  --dsjson              Enable Decision Service JSON parsing
  -k [ --kill_cache ]   Do not reuse existing cache: create a new one always
  --compressed          use gzip format whenever possible. If a cache file is
                        being created, this option creates a compressed cache
                        file. A mixture of raw-text & compressed inputs are
                        supported with autodetection.
  --no_stdin            Do not default to reading from stdin
  --no_daemon           Force a loaded daemon or active learning model to
                        accept local input instead of starting in daemon mode
  --chain_hash          Enable chain hash in JSON for feature name and string
                        feature value. e.g. {'A': {'B': 'C'}} is hashed as
                        A^B^C. Note: this will become the default in a future
                        version, so enabling this option will migrate you to
                        the new behavior and silence the warning.
  --flatbuffer          Data file will be interpreted as a flatbuffer file
OjaNewton Options:
  --OjaNewton                    Online Newton with Oja's Sketch
  --sketch_size arg (=10, )      Size of sketch
  --epoch_size arg (=1, )        Size of epoch
  --alpha arg (=1, )             Mutiplicative constant for indentiy
  --alpha_inverse arg            One over alpha, similar to learning rate
  --learning_rate_cnt arg (=2, ) Constant for the learning rate 1/t
  --normalize arg                Normalize the features or not
  --random_init arg              Randomize initialization of Oja or not
Active Learning Options:
  --active                Enable active learning
  --simulation            Active learning simulation mode
  --mellowness arg (=8, ) Active learning mellowness parameter c_0. Default 8
Active Learning with Cover Options:
  --active_cover                Enable active learning with cover
  --mellowness arg (=8, )       Active learning mellowness parameter c_0.
                                Default 8
  --alpha arg (=1, )            Active learning variance upper bound parameter
                                alpha. Default 1
  --beta_scale arg (=3.16228, ) Active learning variance upper bound parameter
                                beta_scale. Default std::sqrt(10)
  --cover arg (=12, )           Cover size. Default 12
  --oracular                    Use Oracular-CAL style query or not. Default
                                false
Audit Regressor Options:
  --audit_regressor arg Stores feature names and their regressor values. Same
                        dataset must be used for both regressor training and
                        this mode.
Autolink Options:
  --autolink arg        Create link function with polynomial d
Automl Options:
  --automl arg (=3, )                Set number of live configs
  --global_lease arg (=10, )         Set initial lease for automl interactions
  --cm_type arg (=interaction, )     Set type of config manager. Choices:
                                     {interaction}
  --priority_type arg (=none, )      Set function to determine next config.
                                     Choices: {least_exclusion, none}
  --priority_challengers arg (=-1, ) Set number of priority challengers to use
  --keep_configs                     keep all configs after champ change
  --oracle_type arg (=one_diff, )    Set oracle to generate configs. Choices:
                                     {one_diff, rand}
Baseline Options:
  --baseline            Learn an additive baseline (from constant features) and
                        a residual separately in regression
  --lr_multiplier arg   Learning rate multiplier for baseline model
  --global_only         Use separate example with only global constant for
                        baseline predictions
  --check_enabled       Only use baseline when the example contains enabled
                        flag
Baseline challenger reduction: Build a CI around the baseline action and use it instead of the model if it's perfoming better Options:
  --baseline_challenger_cb   Enable reduction
  --cb_c_alpha arg (=0.05, ) Confidence level for
  --cb_c_tau arg (=0.999, )  Time constant for count decay
Conjugate Gradient Options:
  --conjugate_gradient  Use conjugate gradient based optimization
LBFGS and Conjugate Gradient Options:
  --bfgs                       Use conjugate gradient based optimization
  --hessian_on                 Use second derivative in line search
  --mem arg (=15, )            Memory in bfgs
  --termination arg (=0.001, ) Termination threshold
Binary Loss Options:
  --binary              Report loss as binary classification on -1,1
Boosting Options:
  --boosting arg        Online boosting with <N> weak learners
  --gamma arg (=0.1, )  Weak learner's edge (=0.1), used only by online BBM
  --alg arg (=BBM, )    Specify the boosting algorithm: BBM (default), logistic
                        (AdaBoost.OL.W), adaptive (AdaBoost.OL). Choices: {BBM,
                        adaptive, logistic}
Bootstrap Options:
  --bootstrap arg       K-way bootstrap by online importance resampling
  --bs_type arg         Prediction type. Choices: {mean, vote}
Continuous Actions Tree with Smoothing Options:
  --cats arg            Number of discrete actions <k> for cats
  --min_value arg       Minimum continuous value
  --max_value arg       Maximum continuous value
  --bandwidth arg       Bandwidth (radius) of randomization around discrete
                        actions in terms of continuous range. By default will
                        be set to half of the continuous action unit-range
                        resulting in smoothing that stays inside the action
                        space unit-range:
                        unit_range = (max_value - min_value)/num-of-actions
                        default bandwidth = unit_range / 2.0
Continuous Action Tree with Smoothing with Full Pdf Options:
  --cats_pdf arg        Number of tree labels <k> for cats_pdf
CATS Tree Options:
  --cats_tree arg             CATS Tree with <k> labels
  --tree_bandwidth arg (=0, ) Tree bandwidth for continuous actions in terms of
                              #actions
  --link arg                  The learner in each node must return a prediction
                              in range [-1,1], so only glf1 is allowed.
                              Choices: {glf1}
Contextual Bandit Options:
  --cb arg              Use contextual bandit learning with <k> costs
  --cb_type arg (=dr, ) Contextual bandit method to use. Choices: {dm, dr, ips,
                        mtr, sm}
  --eval                Evaluate a policy rather than optimizing
  --cb_force_legacy     Default to non-adf cb implementation (cb_to_cb_adf)
Contextual Bandit with Action Dependent Features Options:
  --cb_adf               Do Contextual Bandit learning with multiline action
                         dependent features
  --rank_all             Return actions sorted by score order
  --no_predict           Do not do a prediction when training
  --clip_p arg (=0, )    Clipping probability in importance weight. Default:
                         0.f (no clipping)
  --cb_type arg (=mtr, ) Contextual bandit method to use. Choices: {dm, dr,
                         ips, mtr, sm}
CB Distributionally Robust Optimization Options:
  --cb_dro                     Use DRO for cb learning
  --cb_dro_alpha arg (=0.05, ) Confidence level for cb dro
  --cb_dro_tau arg (=0.999, )  Time constant for count decay for cb dro
  --cb_dro_wmax arg (=inf, )   Maximum importance weight for cb_dro
Contextual Bandit Exploration Options:
  --cb_explore arg        Online explore-exploit for a <k> action contextual
                          bandit problem
  --first arg             Tau-first exploration
  --epsilon arg (=0.05, ) Epsilon-greedy exploration
  --bag arg               Bagging-based exploration
  --cover arg             Online cover based exploration
  --nounif                Do not explore uniformly on zero-probability actions
                          in cover
  --psi arg (=1, )        Disagreement parameter for cover
Contextual Bandit Exploration with ADF (bagging) Options:
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem
                        with multiline action dependent features
  --epsilon arg         Epsilon-greedy exploration
  --bag arg             Bagging-based exploration
  --greedify            Always update first policy once in bagging
  --first_only          Only explore the first action in a tie-breaking event
Contextual Bandit Exploration with ADF (online cover) Options:
  --cb_explore_adf        Online explore-exploit for a contextual bandit
                          problem with multiline action dependent features
  --cover arg             Online cover based exploration
  --psi arg (=1, )        Disagreement parameter for cover
  --nounif                Do not explore uniformly on zero-probability actions
                          in cover
  --first_only            Only explore the first action in a tie-breaking event
  --cb_type arg (=mtr, )  Contextual bandit method to use. Choices: {dr, ips,
                          mtr}
  --epsilon arg (=0.05, ) Epsilon-greedy exploration
Contextual Bandit Exploration with ADF (tau-first) Options:
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem
                        with multiline action dependent features
  --first arg           Tau-first exploration
  --epsilon arg         Epsilon-greedy exploration
Contextual Bandit Exploration with ADF (greedy) Options:
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem
                        with multiline action dependent features
  --epsilon arg         Epsilon-greedy exploration
  --first_only          Only explore the first action in a tie-breaking event
Contextual Bandit Exploration with ADF (RegCB) Options:
  --cb_explore_adf          Online explore-exploit for a contextual bandit
                            problem with multiline action dependent features
  --regcb                   RegCB-elim exploration
  --regcbopt                RegCB optimistic exploration
  --mellowness arg (=0.1, ) RegCB mellowness parameter c_0. Default 0.1
  --cb_min_cost arg (=0, )  Lower bound on cost
  --cb_max_cost arg (=1, )  Upper bound on cost
  --first_only              Only explore the first action in a tie-breaking
                            event
  --cb_type arg (=mtr, )    Contextual bandit method to use. RegCB only
                            supports supervised regression (mtr). Choices:
                            {mtr}
Contextual Bandit Exploration with ADF (rnd) Options:
  --cb_explore_adf             Online explore-exploit for a contextual bandit
                               problem with multiline action dependent features
  --epsilon arg                Minimum exploration probability
  --rnd arg                    Rnd based exploration
  --rnd_alpha arg (=0.1, )     CI width for rnd (bigger => more exploration on
                               repeating features)
  --rnd_invlambda arg (=0.1, ) Covariance regularization strength rnd (bigger
                               => more exploration on new features)
Contextual Bandit Exploration with ADF (softmax) Options:
  --cb_explore_adf      Online explore-exploit for a contextual bandit problem
                        with multiline action dependent features
  --epsilon arg         Epsilon-greedy exploration
  --softmax             Softmax exploration
  --lambda arg (=1, )   Parameter for softmax
Contextual Bandit Exploration with ADF (SquareCB) Options:
  --cb_explore_adf              Online explore-exploit for a contextual bandit
                                problem with multiline action dependent
                                features
  --squarecb                    SquareCB exploration
  --gamma_scale arg (=10, )     Sets SquareCB greediness parameter to
                                gamma=[gamma_scale]*[num examples]^1/2
  --gamma_exponent arg (=0.5, ) Exponent on [num examples] in SquareCB
                                greediness parameter gamma
  --elim                        Only perform SquareCB exploration over
                                plausible actions (computed via RegCB strategy)
  --mellowness arg (=0.001, )   Mellowness parameter c_0 for computing
                                plausible action set. Only used with --elim
  --cb_min_cost arg (=0, )      Lower bound on cost. Only used with --elim
  --cb_max_cost arg (=1, )      Upper bound on cost. Only used with --elim
  --cb_type arg (=mtr, )        Contextual bandit method to use. SquareCB only
                                supports supervised regression (mtr). Choices:
                                {mtr}
Contextual Bandit Exploration with ADF (synthetic cover) Options:
  --cb_explore_adf              Online explore-exploit for a contextual bandit
                                problem with multiline action dependent
                                features
  --epsilon arg                 Epsilon-greedy exploration
  --synthcover                  Use synthetic cover exploration
  --synthcoverpsi arg (=0.1, )  Exploration reward bonus
  --synthcoversize arg (=100, ) Number of policies in cover
Continuous Actions: cb_explore_pdf Options:
  --cb_explore_pdf        Sample a pdf and pick a continuous valued action
  --epsilon arg (=0.05, ) Epsilon-greedy exploration
  --min_value arg (=0, )  Min value for continuous range
  --max_value arg (=1, )  Max value for continuous range
  --first_only            Use user provided first action or user provided pdf
                          or uniform random
CB Sample Options:
  --cb_sample           Sample from CB pdf and swap top action
Contextual Bandit: cb -> cb_adf Options:
  --cb_to_cbadf arg     Maps cb_adf to cb. Disable with cb_force_legacy
  --cb arg              Maps cb_adf to cb. Disable with cb_force_legacy
  --cb_explore arg      Translate cb explore to cb_explore_adf. Disable with
                        cb_force_legacy
  --cbify arg           Translate cbify to cb_adf. Disable with cb_force_legacy
  --cb_force_legacy     Default to non-adf cb implementation (cb_algs)
Make Multiclass into Contextual Bandit Options:
  --cbify arg                  Convert multiclass on <k> classes into a
                               contextual bandit problem
  --cbify_cs                   Consume cost-sensitive classification examples
                               instead of multiclass
  --cbify_reg                  Consume regression examples instead of
                               multiclass and cost sensitive
  --cats arg (=0, )            Continuous action tree with smoothing
  --cb_discrete                Discretizes continuous space and adds cb_explore
                               as option
  --min_value arg              Minimum continuous value
  --max_value arg              Maximum continuous value
  --loss_option arg (=0, )     Loss options for regression - 0:squared,
                               1:absolute, 2:0/1
  --loss_report arg (=0, )     Loss report option - 0:normalized,
                               1:denormalized
  --loss_01_ratio arg (=0.1, ) Ratio of zero loss for 0/1 loss
  --loss0 arg (=0, )           Loss for correct label
  --loss1 arg (=1, )           Loss for incorrect label
  --flip_loss_sign             Flip sign of loss (use reward instead of loss)
Make csoaa_ldf into Contextual Bandit Options:
  --cbify_ldf           Convert csoaa_ldf into a contextual bandit problem
  --loss0 arg (=0, )    Loss for correct label
  --loss1 arg (=1, )    Loss for incorrect label
Continuous Action Contextual Bandit using Zeroth-Order Optimization Options:
  --cbzo                   Solve 1-slot Continuous Action Contextual Bandit
                           using Zeroth-Order Optimization
  --policy arg (=linear, ) Policy/Model to Learn
  --radius arg (=0.1, )    Exploration Radius
Conditional Contextual Bandit Exploration with ADF Options:
  --ccb_explore_adf      Do Conditional Contextual Bandit learning with
                         multiline action dependent features.
  --all_slots_loss       Report average loss from all slots
  --no_predict           Do not do a prediction when training
  --cb_type arg (=mtr, ) Contextual bandit method to use. Choices: {dm, dr,
                         ips, mtr, sm}
Importance Weight Classes Options:
  --classweight arg     Importance weight multiplier for class
Confidence Options:
  --confidence                 Get confidence for binary predictions
  --confidence_after_training  Confidence after training
count_label Options:
  --dont_output_best_constant  Don't track the best constant used in the output
Cost Sensitive Active Learning Options:
  --cs_active arg                       Cost-sensitive active learning with <k>
                                        costs
  --simulation                          Cost-sensitive active learning
                                        simulation mode
  --baseline                            Cost-sensitive active learning baseline
  --domination arg (=1, )               Cost-sensitive active learning use
                                        domination. Default 1
  --mellowness arg (=0.1, )             Mellowness parameter c_0. Default 0.1
  --range_c arg (=0.5, )                Parameter controlling the threshold for
                                        per-label cost uncertainty. Default 0.5
  --max_labels arg (=18446744073709551615, )
                                        Maximum number of label queries
  --min_labels arg (=18446744073709551615, )
                                        Minimum number of label queries
  --cost_max arg (=1, )                 Cost upper bound. Default 1
  --cost_min arg (=0, )                 Cost lower bound. Default 0
  --csa_debug                           Print debug stuff for cs_active
Cost Sensitive One Against All Options:
  --csoaa arg           One-against-all multiclass with <k> costs
  --indexing arg        Choose between 0 or 1-indexing. Choices: {0, 1}
Cost Sensitive One Against All with Label Dependent Features Options:
  --csoaa_ldf arg       Use one-against-all multiclass learning with label
                        dependent features
  --ldf_override arg    Override singleline or multiline from csoaa_ldf or
                        wap_ldf, eg if stored in file
  --csoaa_rank          Return actions sorted by score order
  --probabilities       Predict probabilities of all classes
Cost Sensitive Weighted All-Pairs with Label Dependent Features Options:
  --wap_ldf arg         Use weighted all-pairs multiclass learning with label
                        dependent features.  Specify singleline or multiline.
Error Correcting Tournament Options:
  --ect arg                Error correcting tournament with <k> labels
  --error arg (=0, )       Errors allowed by ECT
  --link arg (=identity, ) Specify the link function. Choices: {glf1, identity,
                           logistic, poisson}
Interaction Grounded Learning Options:
  --experimental_igl    Experimental: Do Interaction Grounding with multiline
                        action dependent features.
Explore Evaluation Options:
  --explore_eval        Evaluate explore_eval adf policies
  --multiplier arg      Multiplier used to make all rejection sample
                        probabilities <= 1
Debug: Metrics Options:
  --extra_metrics arg   Specify filename to write metrics to. Note: There is no
                        fixed schema
FreeGrad Options:
  --freegrad            Diagonal FreeGrad Algorithm
  --restart             Use the FreeRange restarts
  --project             Project the outputs to adapt to both the lipschitz and
                        comparator norm
  --radius arg          Radius of the l2-ball for the projection. If not
                        supplied, an adaptive radius will be used.
  --fepsilon arg (=1, ) Initial wealth
Follow the Regularized Leader Options:
  --ftrl                FTRL: Follow the Proximal Regularized Leader
  --coin                Coin betting optimizer
  --pistol              PiSTOL: Parameter-free STOchastic Learning
  --ftrl_alpha arg      Learning rate for FTRL optimization
  --ftrl_beta arg       Learning rate for FTRL optimization
Gradient Descent Options:
  --sgd                  Use regular stochastic gradient descent update
  --adaptive             Use adaptive, individual learning rates
  --adax                 Use adaptive learning rates with x^2 instead of g^2x^2
  --invariant            Use safe/importance aware updates
  --normalized           Use per feature normalized updates
  --sparse_l2 arg (=0, ) Degree of l2 regularization applied to activated
                         sparse parameters
  --l1_state arg (=0, )  Amount of accumulated implicit l1 regularization
  --l2_state arg (=1, )  Amount of accumulated implicit l2 regularization
Scorer Options:
  --link arg (=identity, ) Specify the link function. Choices: {glf1, identity,
                           logistic, poisson}
count_label Options:
  --dont_output_best_constant  Don't track the best constant used in the output
