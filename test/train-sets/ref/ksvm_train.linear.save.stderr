using l2 regularization = 1
final_regressor = models/ksvm.model
Lambda = 1
Kernel = linear
using no cache
Reading datafile = train-sets/rcv1_small50.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled learners: ksvm, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
1.000000 1.000000            1            1.0         1.0000         0.0000       50
1.266901 1.533802            2            2.0        -1.0000         0.5338      103
1.032392 0.797883            4            4.0        -1.0000        -0.4138      134
0.938942 0.845492            8            8.0        -1.0000        -0.4126      145
0.924549 0.910156           16           16.0         1.0000        -0.6626       23
0.906318 0.888087           32           32.0        -1.0000        -0.5203       31

finished run
number of examples = 50
weighted example sum = 50.000000
weighted label sum = -16.000000
average loss = 0.889422
best constant = -1.000000
best constant's loss = 0.680000
total feature number = 4279
Num support = 50
Number of kernel evaluations = 6157 Number of cache queries = 5415
Total loss = 44.471115
