final_regressor = models/sr.model
creating cache_file = train-sets/0001.dat.cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
Enabled reductions: gd, scorer-identity, count_label
Input label = simple
Output pred = scalar
average  since         example        example        current        current  current 
loss     last          counter         weight          label        predict features 
0.235695 0.235695           50           50.0         1.0000         0.4783       21 
0.220808 0.205922          100          100.0         1.0000         0.6434       41 
0.210682 0.190430          150          150.0         1.0000         0.4742       38 
0.182729 0.182729          200          200.0         1.0000         1.0000       88  h
0.167472 0.100343          250          250.0         0.0000         0.0920       41  h
0.175114 0.209499          300          300.0         0.0000         0.0677       14  h
0.179519 0.208593          350          350.0         0.0000         0.0000      122  h

finished run
number of examples per pass = 180
passes used = 2
weighted example sum = 360.000000
weighted label sum = 160.000000
average loss = 0.153098 h
best constant = 0.444444
best constant's loss = 0.246914
total feature number = 27566
