predictions = 0002.autolink.predict
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
Enabled reductions: gd, autolink, scorer-identity
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.271591 0.271591            1            1.0   0.5211   0.0000       15
0.136120 0.000650            2            2.0   0.5353   0.5098       15
0.110789 0.085458            4            4.0   0.5854   0.5854       15
0.072568 0.034346            8            8.0   0.5575   0.4834       15
0.074885 0.077202           16           16.0   0.5878   0.4088       15
0.040576 0.006267           32           32.0   0.6038   0.6158       15
0.024143 0.007710           64           64.0   0.5683   0.4844       15

finished run
number of examples = 100
weighted example sum = 100.000000
weighted label sum = 52.222140
average loss = 0.017487
best constant = 0.522221
total feature number = 1499
