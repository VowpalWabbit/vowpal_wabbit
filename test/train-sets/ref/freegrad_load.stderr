only testing
predictions = freegrad.predict
Enabling FreeGrad based optimization
Algorithm used: FreeGrad
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 800
power_t = 0.5
Enabled reductions: freegrad, scorer-identity, count_label
Input label = simple
Output pred = scalar
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0   1.0000   1.0000       51
0.000000 0.000000            2            2.0   0.0000   0.0000      104
0.000000 0.000000            4            4.0   0.0000   0.0000      135
0.000146 0.000292            8            8.0   0.0000   0.0000      146
0.003041 0.005935           16           16.0   1.0000   1.0000       24
0.006027 0.009014           32           32.0   0.0000   0.0000       32
0.006277 0.006528           64           64.0   0.0000   0.0000       61
0.011065 0.015854          128          128.0   1.0000   1.0000      106

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.016990
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
