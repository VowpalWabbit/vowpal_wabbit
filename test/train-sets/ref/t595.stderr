using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled learners: gd, nn, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.271591 0.271591            1            1.0         0.5211         0.0000       15
0.151242 0.030893            2            2.0         0.5353         0.3595       15
0.078051 0.004859            4            4.0         0.5854         0.5466       15
0.048444 0.018838            8            8.0         0.5575         0.6397       15
0.025055 0.001666           16           16.0         0.5878         0.5551       15
0.015536 0.006017           32           32.0         0.6038         0.5833       15
0.009155 0.002773           64           64.0         0.5683         0.5121       15
0.006940 0.004725          128          128.0         0.5351         0.5473       15
0.004926 0.002913          256          256.0         0.5385         0.5556       15
0.004187 0.003448          512          512.0         0.5053         0.5391       15

finished run
number of examples = 1000
weighted example sum = 1000.000000
weighted label sum = 526.517528
average loss = 0.003325
best constant = 0.526518
total feature number = 14996
