enabling BFGS based optimization **without** curvature calculation
Num weight bits = 18
learning rate = 20
initial_t = 128000
power_t = 1
decay_learning_rate = 1
## avg. loss 	der. mag. 	d. m. cond.	 wolfe1    	wolfe2    	mix fraction	curvature 	dir. magnitude	step size
creating cache_file = test-sets/0001.dat.cache
Reading datafile = test-sets/0001.dat
num sources = 1
Enabled reductions: bfgs, scorer-identity, count_label
Input label = simple
Output pred = scalar
 1 0.23560   	3.13607   	94.68915  	          	          	          	31119.57753	17991.60547	0.00304
Maximum number of passes reached. To optimize further, increase the number of passes

finished run
number of examples per pass = 90
passes used = 2
weighted example sum = 180.000000
weighted label sum = 102.000000
average loss = 0.273508 h
best constant = 0.566667
best constant's loss = 0.245556
total feature number = 52032
