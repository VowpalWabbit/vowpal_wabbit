final_regressor = models/sequence_data.ldf.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/sequence_data.cache
Reading datafile = train-sets/sequence_data
num sources = 1
Enabled reductions: gd, scorer-identity, csoaa_ldf, shared_feature_merger, search_task
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
4.000000   4.000000          1  [5 4 3 2 1           ] [1 1 1 1 1           ]     0     0        5        0       25  0.000000
2.000000   0.000000          2  [5 4 3 2 1           ] [5 4 3 2 1           ]     1     0       10        0       50  0.000000
1.000000   0.000000          4  [5 4 3 2 1           ] [5 4 3 2 1           ]     3     0       20        0      100  0.000001
0.500000   0.000000          8  [5 4 3 2 1           ] [5 4 3 2 1           ]     7     0       40        0      200  0.000002
0.250000   0.000000         16  [5 4 3 2 1           ] [5 4 3 2 1           ]    15     0       80        0      400  0.000004

finished run
number of examples per pass = 1
passes used = 20
weighted example sum = 20.000000
weighted label sum = 0.000000
average loss = 0.200000
total feature number = 1000
