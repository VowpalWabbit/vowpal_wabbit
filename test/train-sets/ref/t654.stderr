using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled learners: gd, scorer-identity, boosting-logistic, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.135795 0.135795            1            1.0         0.5211         0.0000       15
0.068536 0.001276            2            2.0         0.5353         0.0000       15
0.051305 0.034075            4            4.0         0.5854         1.2863       15
0.034308 0.017311            8            8.0         0.5575         2.1921       15
0.036829 0.039349           16           16.0         0.5878         2.2780       15
0.020245 0.003662           32           32.0         0.6038         5.2927       15
0.012819 0.005394           64           64.0         0.5683         4.2469       15
0.007139 0.001459          128          128.0         0.5351         4.7802       15
0.003821 0.000502          256          256.0         0.5385         5.5805       15
0.002067 0.000314          512          512.0         0.5053         5.1782       15

finished run
number of examples = 1000
weighted example sum = 1000.000000
weighted label sum = 526.517528
average loss = 0.001118
best constant = 0.526518
total feature number = 14996
