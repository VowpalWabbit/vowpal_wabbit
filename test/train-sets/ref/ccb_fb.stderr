Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/ccb.fb
num sources = 1
Enabled reductions: gd, generate_interactions, scorer-identity, csoaa_ldf-rank, cb_adf, cb_explore_adf_greedy, cb_sample, shared_feature_merger, ccb_explore_adf
Input label = label_type_t::ccb
Output pred = prediction_type_t::decision_probs
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.000000 0.000000            1            1.0 0:0,1:0,... 0,1,2,...       96
0.000000 0.000000            2            2.0 3:0,4:0,... 3,4,0,...       96
0.000000 0.000000            4            4.0 1:0,4:-1,... 1,4,2,...       96
-0.144345 -0.288690            8            8.0 4:-1,1:0,... 4,1,0,...       96
-0.076984 0.000000           16           16.0  ?,?,... 4,2,1,...       96

finished run
number of examples = 24
weighted example sum = 24.000000
weighted label sum = 0.000000
average loss = -0.076984
total feature number = 2304
