final_regressor = models/cats_room_temp.model
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
using no cache
Reading datafile = train-sets/cats_room_temp.json
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled reductions: ftrl-Coin Betting, scorer-identity, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
Input label = continuous
Output pred = action_pdf_value
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1095.824585 1095.824585            1            1.0 {0.00150219,24.9985,0.005} 0.00150219,0.005        3
582.161686 68.498787            2            2.0 {4.07018,21.0955,0.0675} 2.13947,0.0883333        3
291.080843 0.000000            4            4.0 {72.9376,5.26132,0.005} 41.5384,0.005        3
145.540421 0.000000            8            8.0 {67.1305,2.93452,0.0675} 88.2406,0.005        3
72.804541 0.068661           16           16.0 {6.0072,19.3537,0.005} 71.9823,0.005        3
36.480461 0.156381           32           32.0 {59.5709,0.916027,0.0675} 51.4435,0.0883333        3
18.247755 0.015050           64           64.0 {23.3977,7.0768,0.005} 49.4066,0.0883333        3

finished run
number of examples = 100
weighted example sum = 100.000000
weighted label sum = 100.000000
average loss = 11.691978
total feature number = 300
Learn() count per node: id=0, #l=32; id=1, #l=18; id=2, #l=44; id=3, #l=10; id=4, #l=20; id=5, #l=48; id=6, #l=12; id=7, #l=8; id=8, #l=6; id=9, #l=7; id=10, #l=18; id=11, #l=28; id=12, #l=9; id=13, #l=9; id=14, #l=3; id=15, #l=0; 
