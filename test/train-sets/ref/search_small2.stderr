Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/seq_small2.cache
Reading datafile = train-sets/seq_small2
num sources = 1
Enabled reductions: gd, scorer-identity, csoaa, search_task
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
3.000000   3.000000          1  [4 3 1 2             ] [1 1 1 1             ]     0     0        4        0        4  0.000000
1.500000   0.000000          2  [4 3 1 2             ] [4 3 1 2             ]     1     0        8        0        8  0.000000
0.750000   0.000000          4  [4 3 1 2             ] [4 3 1 2             ]     3     0       16        0       16  0.000000

finished run
number of examples per pass = 1
passes used = 4
weighted example sum = 4.000000
weighted label sum = 0.000000
average loss = 0.750000
total feature number = 48
