Generating 2-grams for all namespaces.
Generating 4-skips for all namespaces.
Num weight bits = 24
learning rate = 0.25
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/rcv1_raw_cb_small.vw
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
*estimate* *estimate*                                                avglossreg last pred  last correct
2.000000   2.000000          1      1.0    known        1      280   1.000000   0.000000   1.000000  
1.000000   0.000000          2      2.0    known        2      598   0.500501   0.031652   0.000000  
0.500000   0.000000          4      4.0    known        2      784   0.250859   0.026338   0.000000  
0.250000   0.000000          8      8.0    known        2      850   0.247192   0.081576   0.000000  
0.620259   0.990518         16     16.0    known        2      118   0.470154   0.080142   1.000000  
0.324506   0.028753         32     32.0    known        1      166   0.388254   0.047747   0.000000  
0.334902   0.345299         64     64.0    known        1      340   0.391276   0.242109   1.000000  
0.258627   0.182351        128    128.0    known        2      610   0.317785   0.240497   1.000000  
0.214591   0.170556        256    256.0    known        2      712   0.294125   0.529288   0.000000  
0.186576   0.158562        512    512.0    known        1      424   0.265850   0.312602   1.000000  

finished run
number of examples per pass = 1000
passes used = 1
weighted example sum = 1000
weighted label sum = 0
average loss = 0.129796
total feature number = 440020
