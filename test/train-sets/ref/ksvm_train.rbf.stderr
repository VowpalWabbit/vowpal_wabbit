using l2 regularization = 1
Lambda = 1
Kernel = rbf
bandwidth = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
predictions = ksvm_train.rbf.predict
using no cache
Reading datafile = train-sets/rcv1_smaller.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000       50
1.077464   1.154928            2         2.0  -1.0000   0.1549      103
1.003068   0.928672            4         4.0  -1.0000  -0.1453      134
0.944367   0.885665            8         8.0  -1.0000  -0.2848      145
0.929273   0.914179           16        16.0   1.0000  -0.4176       23
0.917699   0.906124           32        32.0  -1.0000  -0.3805       31
0.904987   0.892275           64        64.0  -1.0000  -0.5601       60
0.924562   0.944137          128       128.0   1.0000  -0.1724      105

finished run
number of examples = 250
weighted example sum = 250
weighted label sum = -22
average loss = 0.888309
best constant = -0.088
best constant's loss = 0.992256
total feature number = 19870
Num support = 250
Number of kernel evaluations = 192975 Number of cache queries = 172366
Total loss = 222.077
Done freeing model
Done freeing kernel params
Done with finish 
