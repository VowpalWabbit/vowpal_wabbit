memory_tree: max_nodes = 10 max_leaf_examples = 33 alpha = 0.1 oas = 0 online =0 
Num weight bits = 15
learning rate = 0.001
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/rcv1_smaller.dat.cache
Reading datafile = train-sets/rcv1_smaller.dat
num sources = 1
Enabled reductions: gd, scorer-identity, memory_tree
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0        1        0       50
1.000000     n.a.            2            2.0  unknown        1      103
1.000000     n.a.            4            4.0  unknown        1      134
0.500000 0.000000            8            8.0  unknown        1      145
0.200000 0.000000           16           16.0        1        1       23
0.090909 0.000000           32           32.0  unknown        1       31
0.043478 0.000000           64           64.0  unknown        1       60
0.018868 0.000000          128          128.0        1        1      105
0.008621 0.000000          256          256.0        1        1       30

finished run
number of examples per pass = 250
passes used = 2
weighted example sum = 500.000000
weighted label sum = 0.000000
average loss = 0.004386
total feature number = 39740
