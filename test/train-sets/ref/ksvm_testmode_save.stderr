using l2 regularization = 1
final_regressor = models/ksvm_testmode.model
Lambda = 1
Kernel = linear
using no cache
Reading datafile = train-sets/ksvm_simple.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled learners: ksvm, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
1.000000 1.000000            1            1.0         1.0000         0.0000        3
0.833333 0.666667            2            2.0        -1.0000        -0.3333        3
0.486008 0.138683            4            4.0        -1.0000        -0.8498        3
0.323746 0.161483            8            8.0        -1.0000        -0.8529        3
0.185827 0.047908           16           16.0        -1.0000        -1.0514        3

finished run
number of examples = 20
weighted example sum = 20.000000
weighted label sum = 0.000000
average loss = 0.163565
best constant = -1.000000
best constant's loss = 1.000000
total feature number = 60
Num support = 13
Number of kernel evaluations = 415 Number of cache queries = 354
Total loss = 3.271309
