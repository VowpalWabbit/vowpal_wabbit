using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled reductions: gd, scorer-identity, count_label
Input label = simple
Output pred = scalar
average  since         example        example        current        current  current 
loss     last          counter         weight          label        predict features 
1.000000 1.000000            1            1.0         1.0000         0.0000       51 
0.513618 0.027235            2            2.0         0.0000         0.1650      104 
0.349751 0.022016            3            3.0         0.0000         0.1484       57 
0.211121 0.003177            5            5.0         0.0000         0.0559      131 
0.237736 0.282096            8            8.0         0.0000         0.2024      146 
0.217917 0.178278           12           12.0         0.0000         0.2456      209 
0.249518 0.312718           18           18.0         0.0000         0.2878       29 
0.246780 0.241305           27           27.0         0.0000         0.2217      197 
0.225380 0.184109           41           41.0         0.0000         0.2652       20 
0.235016 0.253827           62           62.0         0.0000         0.4044       96 
0.215732 0.177165           93           93.0         1.0000         0.9321       58 
0.218306 0.223399          140          140.0         0.0000         0.3486       82 

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.195759
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
