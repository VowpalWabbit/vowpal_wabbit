warning: multiplicative --progress <float>: 0.5 is <= 1.0: adding 1.0
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Enabled reductions: gd, scorer-identity
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000       51
0.513618 0.027236            2            2.0   0.0000   0.1650      104
0.349751 0.022016            3            3.0   0.0000   0.1484       57
0.211121 0.003176            5            5.0   0.0000   0.0559      131
0.237739 0.282102            8            8.0   0.0000   0.2024      146
0.217918 0.178278           12           12.0   0.0000   0.2456      209
0.249520 0.312723           18           18.0   0.0000   0.2878       29
0.246782 0.241307           27           27.0   0.0000   0.2217      197
0.225381 0.184107           41           41.0   0.0000   0.2652       20
0.235017 0.253830           62           62.0   0.0000   0.4044       96
0.215733 0.177164           93           93.0   1.0000   0.9322       58
0.218306 0.223399          140          140.0   0.0000   0.3486       82

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.195760
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
