using l1 regularization = 0.2
using l2 regularization = 0.3
final_regressor = models/cbzo_linear.model
Num weight bits = 18
learning rate = 0.0001
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/cbzo_linear.dat
num sources = 1
Enabled reductions: cbzo
Input label = continuous
Output pred = pdf
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.134630 0.134630            1            1.0 {-0.1,0.13463,3.35544e+07} -0.100000009--0.099999994:33554432,0.099999994-0.100000009:33554432        5
0.252245 0.369860            2            2.0 {-0.10036,0.36986,3.35544e+07} -0.100362256--0.100362241:33554432,0.0996377468-0.0996377617:33554432        5
1.868347 3.484450            4            4.0 {-0.14465,4.1984,1.67772e+07} -0.144653514--0.144653484:16777216,0.0553464927-0.0553465001:67108864        5
4.460369 7.052391            8            8.0 {0.14041,3.2148,1.67772e+07} -0.0595940724--0.059594065:67108864,0.140405923-0.140405953:16777216        5
4.564887 4.669406           16           16.0 {0.29141,4.6161,8.38861e+06} 0.0914066732-0.0914066881:33554432,0.291406661-0.291406721:8388608        5
3.839800 3.114712           32           32.0 {0.5117,7.3534,4.1943e+06} 0.31170249-0.311702549:8388608,0.511702478-0.511702597:4194304        5
5.337427 6.835055           64           64.0 {-0.20481,15.314,1.67772e+07} -0.204805627--0.204805598:16777216,-0.0048056026--0.00480560167:536870912        5
5.115217 4.893006          128          128.0 {-0.14471,0.16944,1.67772e+07} -0.144706592--0.144706562:16777216,0.0552934222-0.0552934296:67108864        5
3.413171 1.711126          256          256.0 {1.1829,2.9914,2.09715e+06} 1.18289244-1.18289268:2097152,1.38289249-1.38289273:2097152        5

finished run
number of examples = 500
weighted example sum = 500.000000
weighted label sum = 500.000000
average loss = 2.206201
total feature number = 2500
