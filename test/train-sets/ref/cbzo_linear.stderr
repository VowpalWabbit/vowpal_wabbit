using l1 regularization = 0.2
using l2 regularization = 0.3
final_regressor = models/cbzo_linear.model
using no cache
Reading datafile = train-sets/cbzo_linear.dat
num sources = 1
Num weight bits = 18
learning rate = 0.0001
initial_t = 0
power_t = 0.5
Enabled reductions: cbzo
Input label = continuous
Output pred = PDF
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.134630 0.134630            1            1.0 {-0.1,0.134... -0.1--0.1:3...        5
0.252245 0.369860            2            2.0 {-0.10036,0... -0.1--0.1:3...        5
1.868347 3.484450            4            4.0 {-0.14465,4... -0.14--0.14...        5
4.460369 7.052391            8            8.0 {0.14041,3.... -0.06--0.06...        5
4.564887 4.669406           16           16.0 {0.29141,4.... 0.09-0.09:3...        5
3.839800 3.114712           32           32.0 {0.5117,7.3... 0.31-0.31:8...        5
5.337427 6.835055           64           64.0 {-0.20481,1... -0.2--0.2:1...        5
5.115217 4.893006          128          128.0 {-0.14471,0... -0.14--0.14...        5
3.413171 1.711126          256          256.0 {1.1829,2.9... 1.18-1.18:2...        5

finished run
number of examples = 500
weighted example sum = 500.000000
weighted label sum = 500.000000
average loss = 2.206201
total feature number = 2500
