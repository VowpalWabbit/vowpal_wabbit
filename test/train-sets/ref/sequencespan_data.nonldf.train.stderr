final_regressor = models/sequencespan_data.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/sequencespan_data.cache
Reading datafile = train-sets/sequencespan_data
num sources = 1
Enabled reductions: gd, scorer-identity, csoaa, search_task
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
6.000000   6.000000          1  [2 1 1 2 2 1 6 7 7 ..] [1 1 1 1 1 1 1 1 1 ..]     0     0       15        0       15  0.000000
8.500000   11.000000         2  [2 1 1 2 2 1 6 7 7 ..] [2 1 6 4 1 6 4 1 6 ..]     1     0       30        0       30  0.000000
6.000000   3.500000          4  [2 1 1 2 2 1 6 7 7 ..] [2 1 1 2 2 1 6 7 7 ..]     3     0       60        0       60  0.000000
3.000000   0.000000          8  [2 1 1 2 2 1 6 7 7 ..] [2 1 1 2 2 1 6 7 7 ..]     7     0      120        0      120  0.000000
1.500000   0.000000         16  [2 1 1 2 2 1 6 7 7 ..] [2 1 1 2 2 1 6 7 7 ..]    15     0      240        0      240  0.000000

finished run
number of examples per pass = 1
passes used = 20
weighted example sum = 20.000000
weighted label sum = 0.000000
average loss = 1.200000
total feature number = 900
