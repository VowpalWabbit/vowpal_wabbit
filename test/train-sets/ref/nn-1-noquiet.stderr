using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled reductions: gd, nn, scorer-identity, count_label
Input label = simple
Output pred = scalar
average  since         example        example        current        current  current 
loss     last          counter         weight          label        predict features 
1.000000 1.000000            1            1.0         1.0000         0.0000       51 
0.583630 0.167259            2            2.0         0.0000         0.4090      104 
0.346879 0.110128            4            4.0         0.0000         0.3113      135 
0.273265 0.199652            8            8.0         0.0000         0.2908      146 
0.261051 0.248837           16           16.0         1.0000         0.2922       24 
0.251551 0.242050           32           32.0         0.0000         0.3430       32 
0.244876 0.238201           64           64.0         0.0000         0.3535       61 
0.243891 0.242907          128          128.0         1.0000         0.5382      106 

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.230747
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
