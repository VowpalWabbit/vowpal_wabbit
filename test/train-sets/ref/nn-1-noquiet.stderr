using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled learners: gd, nn, scorer-identity, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
1.000000 1.000000            1            1.0         1.0000         0.0000       51
0.583630 0.167259            2            2.0         0.0000         0.4090      104
0.313712 0.043794            4            4.0         0.0000         0.1536      135
0.289137 0.264562            8            8.0         0.0000         0.2468      146
0.286741 0.284346           16           16.0         1.0000         0.3274       24
0.281299 0.275857           32           32.0         0.0000         0.4074       32
0.271336 0.261372           64           64.0         0.0000         0.3886       61
0.260316 0.249296          128          128.0         1.0000         0.6949      106

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.220732
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
