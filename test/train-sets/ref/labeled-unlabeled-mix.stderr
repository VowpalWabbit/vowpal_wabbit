Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/labeled-unlabeled-mix.dat
num sources = 1
Enabled reductions: gd, scorer-identity, bootstrap
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000        4
1.000000     n.a.            2            2.0  unknown   0.0000        4
1.000000 1.000000            4            4.0  unknown  -0.3884        3

finished run
number of examples = 4
weighted example sum = 4.000000
weighted label sum = 0.000000
average loss = 1.000000
best constant = 0.000000
best constant's loss = 1.000000
total feature number = 14
