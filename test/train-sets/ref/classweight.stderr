using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
Enabled reductions: gd, scorer-identity, classweight-scalar, count_label
Input label = simple
Output pred = scalar
average  since         example        example        current        current  current 
loss     last          counter         weight          label        predict features 
1.000000 1.000000            1            2.0         1.0000         0.0000       51 
0.409460 0.028467            2            5.1         0.0000         0.1687      104 
0.192019 0.013156            4           11.3         0.0000         0.0578      135 
0.174327 0.156634            8           22.6         0.0000         0.2153      146 
0.196851 0.218513           17           46.1         1.0000         0.2846      143 
0.180049 0.163638           34           93.3         0.0000         0.3269      156 
0.195822 0.211445           69          187.5         0.0000         0.2286       88 
0.193539 0.191260          142          375.3         0.0000         0.1285       30 

finished run
number of examples = 200
weighted example sum = 519.899990
weighted label sum = 182.000000
average loss = 0.178875
best constant = 0.350067
best constant's loss = 0.227520
total feature number = 15482
