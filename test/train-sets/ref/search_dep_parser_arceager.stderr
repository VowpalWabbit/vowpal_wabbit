creating cache_file = train-sets/wsj_small.dparser.vw.gz.cache
Reading datafile = train-sets/wsj_small.dparser.vw.gz
num sources = 1
Num weight bits = 20
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
Enabled reductions: gd, scorer-identity, csoaa, search_task
Input label = CS
Output pred = multiclass
average    since      instance            current true      current predicted   cur   cur   predic    cache  examples          
loss       last        counter           output prefix          output prefix  pass   pol     made     hits    gener  beta    
96.000000  96.000000         1  [43:1 5:2 5:2 5:2 1..] [49:1 49:1 49:1 49:..]     0     0       95        0       95  0.000940
51.000000  6.000000          2  [2:2 3:5 5:8 3:7 99..] [2:2 4:2 4:2 5:2 99..]     0     0      102        0      102  0.001009
26.000000  1.000000          4  [2:2 3:5 5:8 3:7 99..] [2:2 3:5 5:1 3:7 99..]     1     0      109        0      204  0.002028
13.250000  0.500000          8  [2:2 3:5 5:8 3:7 99..] [2:2 3:5 5:1 3:7 99..]     3     0      116        0      408  0.004062

finished run
number of examples per pass = 2
passes used = 4
weighted example sum = 8.000000
weighted label sum = 0.000000
average loss = undefined (no holdout)
total feature number = 32707
