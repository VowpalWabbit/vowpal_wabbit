only testing
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 1000
power_t = 0.5
Enabled learners: gd, scorer-identity, boosting-logistic, count_label
Input label = SIMPLE
Output pred = SCALAR
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
0.001260 0.001260            1            1.0         0.5211         2.8708       15
0.000653 0.000046            2            2.0         0.5353         3.1887       15
0.001463 0.002273            4            4.0         0.5854         3.1783       15
0.003501 0.005540            8            8.0         0.5575         2.9302       15
0.003017 0.002533           16           16.0         0.5878         3.4598       15
0.003419 0.003820           32           32.0         0.6038         3.3965       15
0.002554 0.001688           64           64.0         0.5683         3.1982       15
0.002314 0.002074          128          128.0         0.5351         2.9699       15
0.002302 0.002291          256          256.0         0.5385         2.8323       15
0.003557 0.004811          512          512.0         0.5053         3.4287       15

finished run
number of examples = 1000
weighted example sum = 1000.000000
weighted label sum = 526.517528
average loss = 0.002056
best constant = 0.526518
total feature number = 14996
