predictions = offset_tree_001.pred
using no cache
Reading datafile = train-sets/offset_tree_001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
cb_type = dr
Enabled reductions: gd, scorer-identity, csoaa, cb, cb_explore-greedy, ot
Input label = CB
Output pred = ACTION_PROBS
average  since         example        example        current        current  current
loss     last          counter         weight          label        predict features
-1.90125 -1.90125            1            1.0       1:-1:0.5     1:0.950625        2
-0.97500 -0.04875            2            2.0       2:-1:0.5     1:0.950625        2
-0.66666 -0.05000            3            3.0       3:-1:0.5     1:0.950625        2
-0.50000 0.000000            4            4.0        1:0:0.5     2:0.950625        2
-0.40000 0.000000            5            5.0        2:0:0.5     3:0.975000        2
-0.33333 0.000000            6            6.0        3:0:0.5     1:0.950625        2
-0.28571 0.000000            7            7.0        1:0:0.5     3:0.975000        2
-0.25000 0.000000            8            8.0        2:0:0.5     1:0.950625        2
-0.22222 0.000000            9            9.0        3:0:0.5     3:0.975000        2
-0.39012 -1.90125           10           10.0       1:-1:0.5     1:0.950625        2
-0.52750 -1.90125           11           11.0       2:-1:0.5     2:0.950625        2
-0.64604 -1.95000           12           12.0       3:-1:0.5     3:0.975000        2
-0.59634 0.000000           13           13.0        1:0:0.5     2:0.950625        2
-0.55375 0.000000           14           14.0        2:0:0.5     3:0.975000        2
-0.51683 0.000000           15           15.0        3:0:0.5     1:0.950625        2
-0.48453 0.000000           16           16.0        1:0:0.5     3:0.975000        2
-0.45602 0.000000           17           17.0        2:0:0.5     1:0.950625        2
-0.43069 0.000000           18           18.0        3:0:0.5     2:0.950625        2

finished run
number of examples = 18
weighted example sum = 18.000000
weighted label sum = 0.000000
average loss = -0.430694
total feature number = 36
