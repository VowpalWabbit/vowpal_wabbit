predictions = offset_tree_001.pred
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/offset_tree_001.dat
num sources = 1
Enabled reductions: gd, scorer-identity, csoaa, cb, cb_explore-greedy, ot
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
-1.901250 -1.901250            1            1.0 1:-1:0.5 1:0.950625        2
-0.975000 -0.048750            2            2.0 2:-1:0.5 1:0.950625        2
-0.666667 -0.050000            3            3.0 3:-1:0.5 1:0.950625        2
-0.500000 0.000000            4            4.0  1:0:0.5 2:0.950625        2
-0.400000 0.000000            5            5.0  2:0:0.5 3:0.975000        2
-0.333333 0.000000            6            6.0  3:0:0.5 1:0.950625        2
-0.285714 0.000000            7            7.0  1:0:0.5 3:0.975000        2
-0.250000 0.000000            8            8.0  2:0:0.5 1:0.950625        2
-0.222222 0.000000            9            9.0  3:0:0.5 3:0.975000        2
-0.390125 -1.901250           10           10.0 1:-1:0.5 1:0.950625        2
-0.527500 -1.901250           11           11.0 2:-1:0.5 2:0.950625        2
-0.646042 -1.950000           12           12.0 3:-1:0.5 3:0.975000        2
-0.596346 0.000000           13           13.0  1:0:0.5 2:0.950625        2
-0.553750 0.000000           14           14.0  2:0:0.5 3:0.975000        2
-0.516833 0.000000           15           15.0  3:0:0.5 1:0.950625        2
-0.484531 0.000000           16           16.0  1:0:0.5 3:0.975000        2
-0.456029 0.000000           17           17.0  2:0:0.5 1:0.950625        2
-0.430694 0.000000           18           18.0  3:0:0.5 2:0.950625        2

finished run
number of examples = 18
weighted example sum = 18.000000
weighted label sum = 0.000000
average loss = -0.430694
total feature number = 36
