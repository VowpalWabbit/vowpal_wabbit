only testing
predictions = cluster.predict
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = test-sets/0001.dat
num sources = 1
Enabled reductions: gd, scorer-identity, count_label
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.259904 0.259904            1            1.0   0.0000   0.5098       41
0.151312 0.042720            2            2.0   1.0000   0.7933       75
0.095973 0.040633            4            4.0   0.0000   0.1977       44
0.091131 0.086290            8            8.0   0.0000   0.3779       42
0.133106 0.175081           16           16.0   1.0000   0.7235       34
0.136251 0.139395           32           32.0   0.0000   0.2835      210
0.149684 0.163118           64           64.0   1.0000   0.4224       25

finished run
number of examples = 100
weighted example sum = 100.000000
weighted label sum = 57.000000
average loss = 0.138125
best constant = 0.570000
best constant's loss = 0.245100
total feature number = 5069
