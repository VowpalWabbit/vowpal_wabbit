predictions = 0099.predict
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 200
power_t = 0.5
Enabled reductions: gd, scorer-identity, count_label
Input label = simple
Output pred = scalar
average  since         example        example        current        current  current 
loss     last          counter         weight          label        predict features 
0.000000 0.000000            1            1.0         1.0000         1.0000       51 
0.135922 0.271844            2            2.0         0.0000         0.5214      104 
0.120356 0.104789            4            4.0         0.0000         0.1711      135 
0.081709 0.043062            8            8.0         0.0000         0.0000      146 
0.067157 0.052606           16           16.0         1.0000         0.9968       24 
0.041087 0.015017           32           32.0         0.0000         0.1945       32 
0.027057 0.013027           64           64.0         0.0000         0.0000       61 
0.016897 0.006737          128          128.0         1.0000         0.8131      106 

finished run
number of examples = 200
weighted example sum = 200.000000
weighted label sum = 91.000000
average loss = 0.012333
best constant = 0.455000
best constant's loss = 0.247975
total feature number = 15482
