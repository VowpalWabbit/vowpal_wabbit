/*
Copyright (c) 2009 Yahoo! Inc.  All rights reserved.  The copyrights
embodied in the content of this file are licensed under the BSD
(revised) open source license
 */
#include <fstream>
#include <sstream>
#include <float.h>
#ifdef _WIN32
#include <WinSock2.h>
#else
#include <netdb.h>
#endif
#include <string.h>
#include <stdio.h>
#include <assert.h>

#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
#include <xmmintrin.h>
#endif

#include "parse_example.h"
#include "constant.h"
#include "sparse_dense.h"
#include "gd.h"
#include "cache.h"
#include "simple_label.h"
#include "allreduce.h"
#include "accumulate.h"

//#define NORM_ADAPT_RANGE
//#define NORM_ADAPT_RANGE_MAX_MIN
//#define NORM_ADAPT_VAR_UB
//#define NORM_ADAPT_VAR
//#define NORM_ADAPT_VAR_NZ
#define NORM_ADAPT_ELLIPSE_APPROX
//#define NORM_CORR
//#define NORM_CORR_RES
//#define NORM_CORR_DIST
#define NORM_CORR_DIST_RES

using namespace std;

void adaptive_inline_train(vw& all, example* &ec, float update);
void inline_train(vw& all, example* &ec, float update);
void general_adaptive_train(vw&, example* &ec, float update, float power_t);
void general_normalized_adaptive_train(vw& all, example* &ec, float update, float power_t);
void normalized_adaptive_inline_train(vw& all, example* &ec, float update);
void general_norm_corr_adaptive_train(vw& all, example* &ec, float update, float power_t);
void norm_corr_adaptive_inline_train(vw& all, example* &ec, float update);

//nonreentrant
size_t gd_current_pass = 0;

void predict(vw& all, example* ex);
void sync_weights(vw& all);

float last_eta_t = 0;
float last_norm = 0;
float last_error = 0;
float last_update = 0;
size_t next_print = 1;
size_t next_print_mult = 2;

void print_update_status(float t)
{
  if(t >= next_print)
  {
    next_print *= next_print_mult;
    cout << "Last norm:" << last_norm << " eta_t:" << last_eta_t << " error:" << last_error << " update:" << last_update << endl;
  }
}

void learn_gd(void* a, example* ec)
{
  vw* all = (vw*)a;
  assert(ec->in_use);
  if (ec->pass != gd_current_pass)
    {
      if(gd_current_pass == 0 && all->normalized_adaptive_precompute)
      { //we completed the first pass where we were computing the norm
        //reset t in all->sd and example so that this is like if we were starting the first pass
        all->normalized_adaptive_precompute_t = all->sd->t - all->initial_t - ec->global_weight;
        all->sd->t = all->initial_t + ec->global_weight;
        ec->example_t = all->sd->t;

        cout << "Finished Precomputing Norm - Starting Training" << endl;

        //reset evaluation score in case this is non-zero
        all->sd->weighted_examples = 0.;
        all->sd->weighted_labels = 0.;
        all->sd->weighted_unlabeled_examples = 0.;
        all->sd->total_features = 0.;
        all->sd->sum_loss = 0.;
        all->sd->sum_loss_since_last_dump = 0.;
        all->sd->old_weighted_examples = 0.;
        all->sd->dump_interval = exp(1.);
      }
      else {
        if(all->span_server != "") {
	  if(all->adaptive)
	    accumulate_weighted_avg(*all, all->span_server, all->reg);
	  else 
	    accumulate_avg(*all, all->span_server, all->reg, 0);	      
        }
      
        if (all->save_per_pass)
	{
	  sync_weights(*all);
	  save_predictor(*all, all->final_regressor_name, gd_current_pass);
	}
        all->eta *= all->eta_decay_rate;
      }
      gd_current_pass = ec->pass;
    }
  
  if (!command_example(*all, ec))
    {
      predict(*all,ec);
      if (ec->eta_round != 0.)
	{
	  if (all->adaptive)
            if (all->norm_corr_adaptive) {
              if(all->power_t == 0.5)
                norm_corr_adaptive_inline_train(*all,ec,ec->eta_round);
              else
                general_norm_corr_adaptive_train(*all,ec,ec->eta_round,all->power_t);
            }
            else if (all->normalized_adaptive) {
              if(all->power_t == 0.5)
                normalized_adaptive_inline_train(*all,ec,ec->eta_round);
              else
                general_normalized_adaptive_train(*all,ec,ec->eta_round,all->power_t);
            }
	    else if (all->power_t == 0.5 || !all->exact_adaptive_norm)
	      adaptive_inline_train(*all,ec,ec->eta_round);
	    else
	      general_adaptive_train(*all,ec,ec->eta_round,all->power_t);
	  else
	    inline_train(*all, ec, ec->eta_round);
	  if (all->sd->contraction < 1e-10)  // updating weights now to avoid numerical instability
	    sync_weights(*all);
	  
	}
    }
}

void finish_gd(void* a)
{
  vw* all = (vw*)a;
  sync_weights(*all);
  if(all->span_server != "") {
    if(all->adaptive)
      accumulate_weighted_avg(*all, all->span_server, all->reg);
    else
      accumulate_avg(*all, all->span_server, all->reg, 0);
  }
}

void sync_weights(vw& all) {
  if (all.sd->gravity == 0. && all.sd->contraction == 1.)  // to avoid unnecessary weight synchronization
    return;
  uint32_t length = 1 << all.num_bits;
  size_t stride = all.stride;
  for(uint32_t i = 0; i < length && all.reg_mode; i++)
    all.reg.weight_vectors[stride*i] = trunc_weight(all.reg.weight_vectors[stride*i], all.sd->gravity) * all.sd->contraction;
  all.sd->gravity = 0.;
  all.sd->contraction = 1.;
}

bool command_example(vw& all, example* ec) {
  if (ec->indices.index() > 1)
    return false;

  if (ec->tag.index() >= 4 && !strncmp((const char*) ec->tag.begin, "save", 4))
    {//save state
      string final_regressor_name = all.final_regressor_name;

      if ((ec->tag).index() >= 6 && (ec->tag)[4] == '_')
	final_regressor_name = string(ec->tag.begin+5, (ec->tag).index()-5);

      if (!all.quiet)
	cerr << "saving regressor to " << final_regressor_name << endl;
      save_predictor(all, final_regressor_name, 0);

      return true;
    }
  return false;
}

float finalize_prediction(vw& all, float ret) 
{
  if ( nanpattern(ret))
    {
      cout << "you have a NAN!!!!!" << endl;
      return 0.;
    }
  if ( ret > all.sd->max_label )
    return all.sd->max_label;
  if (ret < all.sd->min_label)
    return all.sd->min_label;

  return ret;
}

void finish_example(vw& all, example* ec)
{
  return_simple_example(all, ec);
}

float inline_predict_trunc(vw& all, example* &ec)
{
  float prediction = all.p->lp->get_initial(ec->ld);
  
  weight* weights = all.reg.weight_vectors;
  size_t mask = all.weight_mask;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    prediction += sd_add_trunc(weights,mask,ec->atomics[*i].begin, ec->atomics[*i].end, all.sd->gravity);
  
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    prediction += one_pf_quad_predict_trunc(weights, *temp.begin,
						    ec->atomics[(int)(*i)[1]], mask, all.sd->gravity);
	}
    }
  
  return prediction;
}

float inline_predict(vw& all, example* &ec)
{
  float prediction = all.p->lp->get_initial(ec->ld);

  weight* weights = all.reg.weight_vectors;
  size_t mask = all.weight_mask;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    prediction += sd_add(weights,mask,ec->atomics[*i].begin, ec->atomics[*i].end);
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    prediction += one_pf_quad_predict(weights,*temp.begin,
					      ec->atomics[(int)(*i)[1]],mask);
	}
    }
  
  return prediction;
}

struct string_value {
  float v;
  string s;
  friend bool operator<(const string_value& first, const string_value& second);
};

bool operator<(const string_value& first, const string_value& second)
{
  return fabs(first.v) > fabs(second.v);
}

#include <algorithm>

void print_audit_quad(vw& all, weight* weights, audit_data& page_feature, v_array<audit_data> &offer_features, vector<string_value>& features)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;

  for (audit_data* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      ostringstream tempstream;
      tempstream << page_feature.space << '^' << page_feature.feature << '^' 
		 << ele->space << '^' << ele->feature << ':' << (((halfhash + ele->weight_index)/all.stride) & all.parse_mask)
		 << ':' << ele->x*page_feature.x
		 << ':' << trunc_weight(weights[(halfhash + ele->weight_index) & all.weight_mask], all.sd->gravity) * all.sd->contraction;
      string_value sv = {weights[ele->weight_index & all.weight_mask]*ele->x, tempstream.str()};
      features.push_back(sv);
    }
}

void print_quad(vw& all, weight* weights, feature& page_feature, v_array<feature> &offer_features, vector<string_value>& features)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      ostringstream tempstream;
      tempstream << (((halfhash + ele->weight_index)/all.stride) & all.parse_mask) 
		 << ':' << (ele->x*page_feature.x)
		 << ':' << trunc_weight(weights[(halfhash + ele->weight_index) & all.weight_mask], all.sd->gravity) * all.sd->contraction;
      string_value sv = {weights[ele->weight_index & all.weight_mask]*ele->x, tempstream.str()};
      features.push_back(sv);
    }
}

void print_features(vw& all, example* &ec)
{
  weight* weights = all.reg.weight_vectors;
  size_t stride = all.stride;

  if (all.lda > 0)
    {
      size_t count = 0;
      for (size_t* i = ec->indices.begin; i != ec->indices.end; i++)
	count += ec->audit_features[*i].index() + ec->atomics[*i].index();
      for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
	for (audit_data *f = ec->audit_features[*i].begin; f != ec->audit_features[*i].end; f++)
	  {
	    cout << '\t' << f->space << '^' << f->feature << ':' << (f->weight_index/all.stride & all.parse_mask) << ':' << f->x;
	    for (size_t k = 0; k < all.lda; k++)
	      cout << ':' << weights[(f->weight_index+k) & all.weight_mask];
	  }
      cout << " total of " << count << " features." << endl;
    }
  else
    {
      vector<string_value> features;

      for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
	if (ec->audit_features[*i].begin != ec->audit_features[*i].end)
	  for (audit_data *f = ec->audit_features[*i].begin; f != ec->audit_features[*i].end; f++)
	    {
	      ostringstream tempstream;
	      tempstream << f->space << '^' << f->feature << ':' << (f->weight_index/stride & all.parse_mask) << ':' << f->x;
	      tempstream  << ':' << trunc_weight(weights[f->weight_index & all.weight_mask], all.sd->gravity) * all.sd->contraction;
	      if(all.adaptive)
		tempstream << '@' << weights[(f->weight_index+1) & all.weight_mask];
	      string_value sv = {weights[f->weight_index & all.weight_mask]*f->x, tempstream.str()};
	      features.push_back(sv);
	    }
	else
	  for (feature *f = ec->atomics[*i].begin; f != ec->atomics[*i].end; f++)
	    {
	      ostringstream tempstream;
	      if ( f->weight_index == ((constant*stride)&all.weight_mask))
		tempstream << "Constant:";
	      tempstream << (f->weight_index/stride & all.parse_mask) << ':' << f->x;
	      tempstream << ':' << trunc_weight(weights[f->weight_index & all.weight_mask], all.sd->gravity) * all.sd->contraction;
	      if(all.adaptive)
		tempstream << '@' << weights[(f->weight_index+1) & all.weight_mask];
	      string_value sv = {weights[f->weight_index & all.weight_mask]*f->x, tempstream.str()};
	      features.push_back(sv);
	    }
      for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
	if (ec->audit_features[(int)(*i)[0]].begin != ec->audit_features[(int)(*i)[0]].end)
	  for (audit_data* f = ec->audit_features[(int)(*i)[0]].begin; f != ec->audit_features[(int)(*i)[0]].end; f++)
	    print_audit_quad(all, weights, *f, ec->audit_features[(int)(*i)[1]], features);
	else
	  for (feature* f = ec->atomics[(int)(*i)[0]].begin; f != ec->atomics[(int)(*i)[0]].end; f++)
	    print_quad(all, weights, *f, ec->atomics[(int)(*i)[1]], features);      

      sort(features.begin(),features.end());

      for (vector<string_value>::iterator sv = features.begin(); sv!= features.end(); sv++)
	cout << '\t' << (*sv).s;
      cout << endl;
    }
}

void print_audit_features(vw& all, example* ec)
{
  fflush(stdout);
  print_result(fileno(stdout),ec->final_prediction,-1,ec->tag);
  fflush(stdout);
  print_features(all, ec);
}

void one_pf_quad_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    weights[(halfhash + ele->weight_index) & mask] += update * ele->x;
}

float InvSqrt(float x){
  float xhalf = 0.5f * x;
  int i = *(int*)&x; // store floating-point bits in integer
  i = 0x5f3759d5 - (i >> 1); // initial guess for Newton's method
  x = *(float*)&i; // convert new bits into float
  x = x*(1.5f - xhalf*x*x); // One round of Newton's method
  return x;
}

void one_pf_quad_adaptive_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, float g, example* ec)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  float update2 = g * page_feature.x * page_feature.x;

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      w[1] += update2 * ele->x * ele->x;
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      float t;
      __m128 eta = _mm_load_ss(&w[1]);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&t, eta);
      t *= ele->x;
#else
      float t = ele->x*InvSqrt(w[1]);
#endif
      w[0] += update * t;
    }
}

void one_pf_quad_norm_corr_adaptive_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, float g, example* ec, float label)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  float x2 = page_feature.x * page_feature.x;
  float xy = page_feature.x * label;
  float update2 = g * x2;
  float xtmp = 0.;
  float xtmp2 = 0.;
  float t = 0.;
  float m = 0.;

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      w[1] += update2 * xtmp2;
      w[2] += x2 * xtmp2;
#if defined(NORM_CORR) || defined(NORM_CORR_DIST)
      w[3] += xtmp * xy;
#else
      w[3] += xtmp * xy - w[0] * x2 * xtmp2;
#endif
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      m = w[1];
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&t, eta);
      t *= xtmp;
#else
      t = xtmp*InvSqrt(w[1]);
#endif
#if defined(NORM_CORR) || defined(NORM_CORR_RES)
      w[0] += update * t * fabs(w[3]/w[2]);
#elif defined(NORM_CORR_DIST)
      w[0] += update * t * fabs(w[3]/w[2] - w[0]);
#else
      w[0] += update * t * fabs(w[3]/w[2] + w[0]);
#endif

    }
}

void scale_norm_ellipse_approx_quad(vw& all, example* &ec, feature& page_feature, v_array<feature> &offer_features, float s)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  size_t mask = all.weight_mask;
  weight* weights = all.reg.weight_vectors;

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
  {
    weight* w=&weights[(halfhash + ele->weight_index) & mask];
    w[2] *= s;
  }
}

void scale_norm_ellipse_approx(vw& all, example* &ec, float s)
{
  size_t mask = all.weight_mask;
  weight* weights = all.reg.weight_vectors;
  
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
  {
    feature *f = ec->atomics[*i].begin;
    for (; f != ec->atomics[*i].end; f++)
    {
      weight* w = &weights[f->weight_index & mask];
      w[2] *= s;
    }
  }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
  {
    if (ec->atomics[(int)(*i)[0]].index() > 0) {
      v_array<feature> temp = ec->atomics[(int)(*i)[0]];
      for (; temp.begin != temp.end; temp.begin++) {
        scale_norm_ellipse_approx_quad(all,ec,*temp.begin,ec->atomics[(int)(*i)[1]],s);
      }
    }
  }
}

void update_norm_ellipse_approx_quad(vw& all, example* &ec, feature& page_feature, v_array<feature> &offer_features, float& norm_x)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  size_t mask = all.weight_mask;
  weight* weights = all.reg.weight_vectors;

  float xtmp = 0.;
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
  {
    weight* w=&weights[(halfhash + ele->weight_index) & mask];
    xtmp = fabs(ele->x * page_feature.x);
    if( xtmp > w[2] ) w[2] = xtmp;
    norm_x += xtmp*xtmp/(w[2]*w[2]);
  }
}

void update_norm_ellipse_approx(vw& all, example* &ec)
{
  size_t mask = all.weight_mask;
  weight* weights = all.reg.weight_vectors;
  
  float norm_x = 0.;
  float xtmp = 0.;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
  {
    feature *f = ec->atomics[*i].begin;
    for (; f != ec->atomics[*i].end; f++)
    {
      weight* w = &weights[f->weight_index & mask];
      xtmp = fabs(f->x);
      if( xtmp > w[2] ) w[2] = xtmp;
      norm_x += xtmp*xtmp/(w[2]*w[2]);
    }
  }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
  {
    if (ec->atomics[(int)(*i)[0]].index() > 0) {
      v_array<feature> temp = ec->atomics[(int)(*i)[0]];
      for (; temp.begin != temp.end; temp.begin++) {
        update_norm_ellipse_approx_quad(all,ec,*temp.begin,ec->atomics[(int)(*i)[1]],norm_x);
      }
    }
  }

  if(norm_x > 1.) scale_norm_ellipse_approx(all,ec,sqrt(norm_x));
}

void one_pf_quad_normalized_adaptive_update(vw& all, weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, float g, example* ec, float timestep_inv)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp = 0.;
  float xtmp2 = 0.;
  float t = 0.;
  float m = 0.;
  
  float timestep_inv_sqrt = sqrt(timestep_inv);

  if( all.normalized_adaptive_precompute && ec->pass == 0) {
//#if !defined(NORM_ADAPT_ELLIPSE_APPROX)
    for (feature* ele = offer_features.begin; ele != offer_features.end; ele++) {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
#if defined(NORM_ADAPT_VAR)
      w[2] += x2 * xtmp2;
#elif defined(NORM_ADAPT_VAR_NZ)
      w[2] += x2 * xtmp2;
      w[3] += 1.;
#elif defined(NORM_ADAPT_VAR_UB)
      w[2] += x2 * xtmp2;
      if( fabs(xtmp*page_feature.x) > w[3] ) w[3] = fabs(page_feature.x*xtmp);
#elif defined(NORM_ADAPT_RANGE) || defined(NORM_ADAPT_ELLIPSE_APPROX)
      if( fabs(xtmp*page_feature.x) > w[2] ) w[2] = fabs(page_feature.x*xtmp);
#else
      if( xtmp*page_feature.x > w[2] ) w[2] = page_feature.x*xtmp;
      if( xtmp*page_feature.x < w[3] ) w[3] = page_feature.x*xtmp;
#endif
    }
//#endif
  }
  else {
    for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      w[1] += update2 * xtmp2;
//#if !defined(NORM_ADAPT_ELLIPSE_APPROX)
      if(!all.normalized_adaptive_precompute) {
#if defined(NORM_ADAPT_VAR)
        w[2] += x2 * xtmp2;
#elif defined(NORM_ADAPT_VAR_NZ)
        w[2] += x2 * xtmp2;
        w[3] += 1.;
#elif defined(NORM_ADAPT_VAR_UB)
        w[2] += x2 * xtmp2;
        if( fabs(xtmp*page_feature.x) > w[3] ) w[3] = fabs(page_feature.x*xtmp);
#elif defined(NORM_ADAPT_RANGE) || defined(NORM_ADAPT_ELLIPSE_APPROX)
        if( fabs(xtmp*page_feature.x) > w[2] ) w[2] = fabs(page_feature.x*xtmp);
#else
        if( xtmp*page_feature.x > w[2] ) w[2] = page_feature.x*xtmp;
        if( xtmp*page_feature.x < w[3] ) w[3] = page_feature.x*xtmp;
#endif
      }
//#endif
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
#if defined(NORM_ADAPT_VAR)
      m = w[1]*(w[2]*timestep_inv);
#elif defined(NORM_ADAPT_VAR_NZ)
      m = w[1]*(w[2]/w[3]);
#elif defined(NORM_ADAPT_VAR_UB)
      m = w[1]*(w[2]*timestep_inv + w[3]*w[3]*timestep_inv_sqrt);
#else
      m = w[1];
#endif
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&t, eta);
      t *= xtmp;
#else
#if defined(NORM_ADAPT_VAR)
      t = xtmp*InvSqrt(w[1]*(w[2]*timestep_inv));
#elif defined(NORM_ADAPT_VAR_NZ)
      t = xtmp*InvSqrt(w[1]*(w[2]/w[3]));
#elif defined(NORM_ADAPT_VAR_UB)
      t = xtmp*InvSqrt(w[1]*(w[2]*timestep_inv + w[3]*w[3]*timestep_inv_sqrt));
#else
      t = xtmp*InvSqrt(w[1]);
#endif
#endif
#if defined(NORM_ADAPT_VAR) || defined(NORM_ADAPT_VAR_UB) || defined(NORM_ADAPT_VAR_NZ)
      w[0] += update * t;
#elif defined(NORM_ADAPT_RANGE) //|| defined(NORM_ADAPT_ELLIPSE_APPROX)
      w[0] += update * t / w[2];
#elif defined(NORM_ADAPT_ELLIPSE_APPROX)
      w[0] += update * t / (w[2]*all.normalized_adaptive_ellipse_max_norm_x);
#else
      w[0] += update * t / (w[2]-w[3]);
#endif
    }
  }
}

void offset_quad_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, size_t offset)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index + offset;
  update *= page_feature.x;
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    weights[(halfhash + ele->weight_index) & mask] += update * ele->x;
}

void norm_corr_adaptive_inline_train(vw& all, example* &ec, float update)
{
  if (fabs(update) == 0.)
    return;

  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  weight* weights = all.reg.weight_vectors;
  float x = 0.;
  float x2 = 0.;
  float m = 0.;
  float t = 0.;
  float y = ld->label;
  float res = ec->final_prediction-y;
  
  float g = all.loss->getSquareGrad(ec->final_prediction, y) * ld->weight;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          x = f->x;
          x2 = x * x;
	  w[1] += g * x2;
          w[2] += x2;
#if defined(NORM_CORR) || defined(NORM_CORR_DIST)
          w[3] += x * y;
#else
          w[3] += x * res - w[0]*x2;
#endif
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
          m = w[1];
          __m128 eta = _mm_load_ss(&m);
          eta = _mm_rsqrt_ss(eta);
          _mm_store_ss(&t, eta);
          t *= x;
#else
	  t = x*InvSqrt(w[1]);
#endif
#if defined(NORM_CORR) || defined(NORM_CORR_RES)
	  w[0] += update * t * fabs(w[3]/w[2]);
#elif defined(NORM_CORR_DIST)
          w[0] += update * t * fabs(w[3]/w[2] - w[0]);
#else
	  w[0] += update * t * fabs(w[3]/w[2] + w[0]);
#endif
          
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
#if defined(NORM_CORR) || defined(NORM_CORR_DIST)
	    one_pf_quad_norm_corr_adaptive_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, y);
#else
            one_pf_quad_norm_corr_adaptive_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, res);
#endif

	} 
    }
}

void normalized_adaptive_inline_train(vw& all, example* &ec, float update)
{
  if (fabs(update) == 0.)
    return;

  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  weight* weights = all.reg.weight_vectors;
  float x = 0.;
  float x2 = 0.;
  float m = 0.;
  float t = 0.;

  float timestep_inv;
  if(all.normalized_adaptive_precompute && ec->pass > 0)
    timestep_inv = 1./all.normalized_adaptive_precompute_t;
  else if(all.active)
    timestep_inv = 1./all.sd->weighted_unlabeled_examples;
  else
    timestep_inv = 1./ec->example_t;

  float timestep_inv_sqrt = sqrt(timestep_inv);

  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  if( all.normalized_adaptive_precompute && ec->pass == 0) {
//#if defined(NORM_ADAPT_ELLIPSE_APPROX)
//    update_norm_ellipse_approx(all,ec);
//#else
    for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++) {
        weight* w = &weights[f->weight_index & mask];
        x = f->x;
        x2 = x * x;
#if defined(NORM_ADAPT_VAR)
        w[2] += x2;
#elif defined(NORM_ADAPT_VAR_NZ)
        w[2] += x2;
        w[3] += 1.;
#elif defined(NORM_ADAPT_VAR_UB)
        w[2] += x2;
        if( fabs(x) > w[3] ) w[3] = fabs(x);
#elif defined(NORM_ADAPT_RANGE) || defined(NORM_ADAPT_ELLIPSE_APPROX)
        if( fabs(x) > w[2] ) w[2] = fabs(x);
#else
        if( x > w[2] ) w[2] = x;
        if( x < w[3] ) w[3] = x;
#endif
      }
    }
    for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    one_pf_quad_normalized_adaptive_update(all, weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, timestep_inv);
	} 
    }
//#endif
  }
  else {
//#if defined(NORM_ADAPT_ELLIPSE_APPROX)
//   if( !all.normalized_adaptive_precompute ) update_norm_ellipse_approx(all,ec);
//#endif
    for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          x = f->x;
          x2 = x * x;
	  w[1] += g * x2;
          if( !all.normalized_adaptive_precompute ) {
#if defined(NORM_ADAPT_VAR)
            w[2] += x2;
#elif defined(NORM_ADAPT_VAR_NZ)
            w[2] += x2;
            w[3] += 1.;
#elif defined(NORM_ADAPT_VAR_UB)
            w[2] += x2;
            if( fabs(x) > w[3] ) w[3] = fabs(x);
//#elif defined(NORM_ADAPT_ELLIPSE_APPROX)
            //nothing more to do
#elif defined(NORM_ADAPT_RANGE) || defined(NORM_ADAPT_ELLIPSE_APPROX)
            if( fabs(x) > w[2] ) w[2] = fabs(x);
#else
            if( x > w[2] ) w[2] = x;
            if( x < w[3] ) w[3] = x;
#endif
          }
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
#if defined(NORM_ADAPT_VAR)
          m = w[1]*(w[2]*timestep_inv);
#elif defined(NORM_ADAPT_VAR_NZ)
          m = w[1]*(w[2]/w[3]);
#elif defined(NORM_ADAPT_VAR_UB)
          m = w[1]*(w[2]*timestep_inv + w[3]*w[3]*timestep_inv_sqrt);
#else
          m = w[1];
#endif
          __m128 eta = _mm_load_ss(&m);
          eta = _mm_rsqrt_ss(eta);
          _mm_store_ss(&t, eta);
          t *= x;
#else
#if defined(NORM_ADAPT_VAR)
	  t = x*InvSqrt(w[1]*(w[2]*timestep_inv));
#elif defined(NORM_ADAPT_VAR_NZ)
	  t = x*InvSqrt(w[1]*(w[2]/w[3]));
#elif defined(NORM_ADAPT_VAR_UB)
	  t = x*InvSqrt(w[1]*(w[2]*timestep_inv + w[3]*w[3]*timestep_inv_sqrt));
#else
          t = x*InvSqrt(w[1]);
#endif
#endif
#if defined(NORM_ADAPT_VAR) || defined(NORM_ADAPT_VAR_UB) || defined(NORM_ADAPT_VAR_NZ)
	  w[0] += update * t;
#elif defined(NORM_ADAPT_RANGE) //|| defined(NORM_ADAPT_ELLIPSE_APPROX)
	  w[0] += update * t / w[2];
#elif defined(NORM_ADAPT_ELLIPSE_APPROX)
          w[0] += update * t / (w[2] * all.normalized_adaptive_ellipse_max_norm_x);
#else
	  w[0] += update * t / (w[2]-w[3]);
#endif
	}
    }
    for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    one_pf_quad_normalized_adaptive_update(all, weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, timestep_inv);
	} 
    }
  }
}


void adaptive_inline_train(vw& all, example* &ec, float update)
{
  if (fabs(update) == 0.)
    return;

  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  weight* weights = all.reg.weight_vectors;
  
  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
	  w[1] += g * f->x * f->x;
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      float t;
      __m128 eta = _mm_load_ss(&w[1]);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&t, eta);
      t *= f->x;
#else
	  float t = f->x*InvSqrt(w[1]);
#endif
	  w[0] += update * t;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    one_pf_quad_adaptive_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec);
	} 
    }
}


void quad_general_norm_corr_adaptive_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, float g, example* ec, float power_t, float label)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  float xy = page_feature.x * label;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp2 = 0.;
  float xtmp = 0.;
  float t = 0.;
  
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      w[1] += update2 * xtmp2;
      w[2] += x2*xtmp2;
      w[3] += xy*xtmp;
      t = xtmp*powf(w[1],-power_t)*powf(fabs(w[3])/w[2],2.*(1.-power_t));
      w[0] += update * t;
    }
}

void general_norm_corr_adaptive_train(vw& all, example* &ec, float update, float power_t)
{
  if (fabs(update) == 0.)
    return;
  
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  weight* weights = all.reg.weight_vectors;

  float x = 0.;
  float x2 = 0.;  
  float t = 0.;
  float y = ld->label;

  float g = all.loss->getSquareGrad(ec->final_prediction, y) * ld->weight;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          x = f->x;
          x2 = x * x;
	  w[1] += g * x2;
          w[2] += x2;
          w[3] += x*y;
	  t = x*powf(w[1],-power_t)*powf(fabs(w[3])/w[2],2*(1.-power_t));
	  w[0] += update * t;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    quad_general_norm_corr_adaptive_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, power_t, y);
	} 
    }
}

void quad_general_normalized_adaptive_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, float g, example* ec, float power_t, float timestep_inv)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp2 = 0.;
  float xtmp = 0.;
  float t = 0.;
  
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      w[1] += update2 * xtmp2;
      w[2] += x2*xtmp2;
      t = xtmp*powf(w[1],-power_t)*powf(w[2]*timestep_inv,power_t-1.);
      w[0] += update * t;
    }
}

void general_normalized_adaptive_train(vw& all, example* &ec, float update, float power_t)
{
  if (fabs(update) == 0.)
    return;
  
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  weight* weights = all.reg.weight_vectors;

  float x = 0.;
  float x2 = 0.;  
  float t = 0.;
  float timestep_inv;
  if(all.active)
    timestep_inv = 1./all.sd->weighted_unlabeled_examples;
  else
    timestep_inv = 1./ec->example_t;

  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          x = f->x;
          x2 = x * x;
	  w[1] += g * x2;
          w[2] += x2;
	  t = x*powf(w[1],-power_t)*powf(w[2]*timestep_inv,power_t-1.);
	  w[0] += update * t;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    quad_general_normalized_adaptive_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, power_t, timestep_inv);
	} 
    }
}

void quad_general_adaptive_update(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float update, float g, example* ec, float power_t)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  update *= page_feature.x;
  float update2 = g * page_feature.x * page_feature.x;
  
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      w[1] += update2 * ele->x * ele->x;
      float t = ele->x*powf(w[1],-power_t);
      w[0] += update * t;
    }
}

void general_adaptive_train(vw& all, example* &ec, float update, float power_t)
{
  if (fabs(update) == 0.)
    return;
  
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  weight* weights = all.reg.weight_vectors;
  
  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
	  w[1] += g * f->x * f->x;
	  float t = f->x*powf(w[1],-power_t);
	  w[0] += update * t;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    quad_general_adaptive_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update, g, ec, power_t);
	} 
    }
}


float xGx_quad(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float g)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  float xGx = 0.;
  float update2 = g * page_feature.x * page_feature.x;
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      float m = w[1] + update2 * ele->x * ele->x;
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&m, eta);
      float t = ele->x * m;
#else
      float t = ele->x*InvSqrt(w[1] + update2 * ele->x * ele->x);
#endif
      xGx += t * ele->x;
    }
  return xGx;
}

float xGx_general_quad(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float g, float power_t)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  float xGx = 0.;
  float update2 = g * page_feature.x * page_feature.x;
  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      float t = ele->x*powf(w[1] + update2 * ele->x * ele->x,- power_t);
      xGx += t * ele->x;
    }
  return xGx;
}

float compute_general_xGx(vw& all, example* &ec, float power_t)
{//We must traverse the features in _precisely_ the same order as during training.
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  if (g==0) return 1.;

  float xGx = 0.;
  
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
	  float t = f->x*powf(w[1] + g * f->x * f->x,- power_t);
	  xGx += t * f->x;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    xGx += xGx_general_quad(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g, power_t);
	} 
    }
  
  return xGx;
}

float compute_xGx(vw& all, example* &ec)
{//We must traverse the features in _precisely_ the same order as during training.
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  if (g==0) return 1.;

  float xGx = 0.;
  
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      float m = w[1] + g * f->x * f->x;
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&m, eta);
      float t = f->x * m;
#else
	  float t = f->x*InvSqrt(w[1] + g * f->x * f->x);
#endif
	  xGx += t * f->x;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    xGx += xGx_quad(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g);
	} 
    }
  
  return xGx;
}

float xGNx_general_quad(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float g, float power_t, float timestep_inv)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  float xGNx = 0.;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp = 0.;
  float xtmp2 = 0.;
  float t = 0.;

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      t = xtmp*powf(w[1] + update2 * xtmp2,- power_t)*powf((w[2]+x2*xtmp2)*timestep_inv,power_t - 1.);
      xGNx += t * xtmp;
    }
  return xGNx;
}

float xGNx_quad(vw &all, weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float g, float timestep_inv, float& norm_x)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  float xGNx = 0.;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp = 0.;
  float xtmp2 = 0.;
  float m = 0.;
  float t = 0.;
  float range_max = 0.;
  float range_min = 0.;
  float sum_g = 0.;
  float sum_x2 = 0.;

  float timestep_inv_sqrt = sqrt(timestep_inv);

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      sum_g = w[1] + update2 * xtmp2;
      sum_x2 = w[2];
      if(!all.normalized_adaptive_precompute) sum_x2 += x2 * xtmp2;
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
#if defined(NORM_ADAPT_VAR)
      m = sum_g*(sum_x2*timestep_inv);
#elif defined(NORM_ADAPT_VAR_NZ)
      timestep_inv = w[3];
      if(!all.normalized_adaptive_precompute) timestep_inv += 1.;
      timestep_inv = 1./timestep_inv;
      m = sum_g*(sum_x2*timestep_inv);
#elif defined(NORM_ADAPT_VAR_UB)
      range_max = w[3];
      if( fabs(xtmp*page_feature.x) > range_max ) range_max = fabs(xtmp*page_feature.x);
      m = sum_g*(sum_x2*timestep_inv + range_max*range_max*timestep_inv_sqrt);
#else
      m = sum_g;
#endif
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&m, eta);
      t = xtmp * m;
#else
#if defined(NORM_ADAPT_VAR)
      t = xtmp*InvSqrt(sum_g*(sum_x2*timestep_inv));
#elif defined(NORM_ADAPT_VAR_NZ)
      timestep_inv = w[3];
      if(!all.normalized_adaptive_precompute) timestep_inv += 1.;
      timestep_inv = 1./timestep_inv;
      t = xtmp*InvSqrt(sum_g*(sum_x2*timestep_inv));
#elif defined(NORM_ADAPT_VAR_UB)
      range_max = w[3];
      if( fabs(xtmp*page_feature.x) > range_max ) range_max = fabs(xtmp*page_feature.x);
      t = xtmp*InvSqrt(sum_g*(sum_x2*timestep_inv + range_max*range_max*timestep_inv_sqrt));
#else
      t = xtmp*InvSqrt(sum_g);
#endif
#endif
#if defined(NORM_ADAPT_VAR) || defined(NORM_ADAPT_VAR_UB) || defined(NORM_ADAPT_VAR_NZ)
      xGNx += t * xtmp;
#elif defined(NORM_ADAPT_RANGE) || defined(NORM_ADAPT_ELLIPSE_APPROX)
      range_max = w[2];
      if( fabs(xtmp*page_feature.x) > range_max ) range_max = fabs(xtmp*page_feature.x);
      xGNx += t * xtmp / range_max;
      norm_x += xtmp2 * x2 / (range_max*range_max);
#else
      range_max = w[2];
      range_min = w[3];
      if( xtmp*page_feature.x > range_max ) range_max = xtmp*page_feature.x;
      if( xtmp*page_feature.x < range_min ) range_min = xtmp*page_feature.x;
      xGNx += t * xtmp / (range_max-range_min);
#endif
    }
  return xGNx;
}

float xGNCx_general_quad(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float g, float power_t, float label)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  float xGNCx = 0.;
  float xy = page_feature.x * label;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp = 0.;
  float xtmp2 = 0.;
  float t = 0.;

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
      t = xtmp*powf(w[1] + update2 * xtmp2,- power_t)*powf(fabs(w[3]+xy*xtmp)/(w[2]+x2*xtmp2),2.*(1.-power_t));
      xGNCx += t * xtmp;
    }
  return xGNCx;
}

float xGNCx_quad(weight* weights, feature& page_feature, v_array<feature> &offer_features, size_t mask, float g, float label)
{
  size_t halfhash = quadratic_constant * page_feature.weight_index;
  float xGNCx = 0.;
  float xy = page_feature.x * label;
  float x2 = page_feature.x * page_feature.x;
  float update2 = g * x2;
  float xtmp = 0.;
  float xtmp2 = 0.;
  float m = 0.;
  float t = 0.;

  for (feature* ele = offer_features.begin; ele != offer_features.end; ele++)
    {
      weight* w=&weights[(halfhash + ele->weight_index) & mask];
      xtmp = ele->x;
      xtmp2 = xtmp * xtmp;
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      m = w[1] + update2 * xtmp2;
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&m, eta);
      t = xtmp * m;
#else
      t = xtmp*InvSqrt(w[1] + update2 * xtmp2);
#endif
#if defined(NORM_CORR)
      xGNCx += t * xtmp * (fabs(w[3] + xtmp*xy)/(w[2] + xtmp2*x2));
#elif defined(NORM_CORR_DIST)
      xGNCx += t * xtmp * fabs((w[3] + xtmp*xy)/(w[2] + xtmp2*x2) - w[0]);
#elif defined(NORM_CORR_RES)
      xGNCx += t * xtmp * fabs((w[3] + xtmp*xy - w[0]*xtmp2*x2)/(w[2] + xtmp2*x2));
#else
      xGNCx += t * xtmp * fabs((w[3] + xtmp*xy - w[0]*xtmp2*x2)/(w[2] + xtmp2*x2) + w[0]);
#endif
    }
  return xGNCx;
}

float compute_general_xGNx(vw& all, example* &ec, float power_t)
{//We must traverse the features in _precisely_ the same order as during training.
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  if (g==0) return 1.;

  float xGNx = 0.;

  float timestep_inv;
  if(all.active)
    timestep_inv = 1./all.sd->weighted_unlabeled_examples;
  else
    timestep_inv = 1./ec->example_t;
  
  float t = 0;
  float xtmp = 0;
  float xtmp2 = 0.;
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          xtmp = f->x;
          xtmp2 = xtmp * xtmp;
	  t = xtmp*powf(w[1] + g * xtmp2,- power_t)*powf((w[2] + xtmp2)*timestep_inv,power_t - 1.);
	  xGNx += t * xtmp;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    xGNx += xGNx_general_quad(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g, power_t, timestep_inv);
	} 
    }
  
  return xGNx;
}

float compute_general_xGNCx(vw& all, example* &ec, float power_t)
{//We must traverse the features in _precisely_ the same order as during training.
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  float y = ld->label;
  float g = all.loss->getSquareGrad(ec->final_prediction, y) * ld->weight;
  if (g==0) return 1.;

  float xGNCx = 0.;
  
  float t = 0;
  float xtmp = 0;
  float xtmp2 = 0.;
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          xtmp = f->x;
          xtmp2 = xtmp * xtmp;
	  t = xtmp*powf(w[1] + g * xtmp2,- power_t)*powf(fabs(w[3] + xtmp*y)/(w[2] + xtmp2),2.*(1.-power_t));
	  xGNCx += t * xtmp;
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    xGNCx += xGNCx_general_quad(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g, power_t, y);
	} 
    }
  
  return xGNCx;
}

float compute_xGNCx(vw& all, example* &ec)
{//We must traverse the features in _precisely_ the same order as during training.
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  float y = ld->label;
  float res = ec->final_prediction-y;
  float g = all.loss->getSquareGrad(ec->final_prediction, y) * ld->weight;
  if (g==0) return 1.;

  float xGNCx = 0.;

  float m = 0.;
  float xtmp2 = 0.;
  float xtmp = 0.;
  float t = 0.;
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          xtmp = f->x;
          xtmp2 = xtmp * xtmp;
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
      m = (w[1] + g * xtmp2);
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&m, eta);
      t = xtmp * m;
#else
	  t = xtmp*InvSqrt(w[1] + g * xtmp2);
#endif
#if defined(NORM_CORR)
	  xGNCx += t * xtmp * fabs((w[3] + xtmp * y)/(w[2]+xtmp2));
#elif defined(NORM_CORR_DIST)
	  xGNCx += t * xtmp * fabs((w[3] + xtmp * y)/(w[2]+xtmp2) - w[0]);
#elif defined(NORM_CORR_RES)
          xGNCx += t * xtmp * fabs((w[3] + xtmp * res - w[0]*xtmp2)/(w[2]+xtmp2));
#else
          xGNCx += t * xtmp * fabs((w[3] + xtmp * res - w[0]*xtmp2)/(w[2]+xtmp2) + w[0]);
#endif
	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
#if defined(NORM_CORR) || defined(NORM_CORR_DIST)
	    xGNCx += xGNCx_quad(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g, y);
#else
            xGNCx += xGNCx_quad(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g, res);
#endif
	} 
    }
  
  return xGNCx;
}

float compute_xGNx(vw& all, example* &ec)
{//We must traverse the features in _precisely_ the same order as during training.
  size_t mask = all.weight_mask;
  label_data* ld = (label_data*)ec->ld;
  float g = all.loss->getSquareGrad(ec->final_prediction, ld->label) * ld->weight;
  if (g==0) return 1.;

  float xGNx = 0.;

  float timestep_inv;
  if(all.normalized_adaptive_precompute && ec->pass > 0)
    timestep_inv = 1./all.normalized_adaptive_precompute_t;
  else if(all.active)
    timestep_inv = 1./all.sd->weighted_unlabeled_examples;
  else
    timestep_inv = 1./ec->example_t;

  float timestep_inv_sqrt = sqrt(timestep_inv);

  float m = 0.;
  float xtmp2 = 0.;
  float xtmp = 0.;
  float t = 0.;
  float range_max = 0.;
  float range_min = 0.;
  float sum_x2 = 0.;
  float sum_g = 0.;
  float norm_x = 0.;
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++)
	{
	  weight* w = &weights[f->weight_index & mask];
          xtmp = f->x;
          xtmp2 = xtmp * xtmp;
          sum_g = w[1] + g * xtmp2;
          sum_x2 = w[2];
          if(!all.normalized_adaptive_precompute) sum_x2 += xtmp2;
#if defined(__SSE2__) && !defined(VW_LDA_NO_SSE)
#if defined(NORM_ADAPT_VAR)
      m = sum_g*(sum_x2*timestep_inv);
#elif defined(NORM_ADAPT_VAR_NZ)
      timestep_inv = w[3];
      if(!all.normalized_adaptive_precompute) timestep_inv += 1.;
      timestep_inv = 1./timestep_inv;
      m = sum_g*(sum_x2*timestep_inv);
#elif defined(NORM_ADAPT_VAR_UB)
      range_max = w[3];
      if( fabs(xtmp) > range_max ) range_max = fabs(xtmp);
      m = sum_g*(sum_x2*timestep_inv + range_max*range_max*timestep_inv_sqrt);
#else
      m = sum_g;
#endif
      //if(1./timestep_inv >= next_print ) cout << "Weight Index:" << (f->weight_index & mask) << " Sum Grad:" << (w[1] + g * xtmp2) << " Sum x^2:" << (w[2] + xtmp2) << " Prod/t:" << m << endl;
      __m128 eta = _mm_load_ss(&m);
      eta = _mm_rsqrt_ss(eta);
      _mm_store_ss(&m, eta);
      t = xtmp * m;
      //if(1./timestep_inv >= next_print ) cout << "Inv Sqrt:" << m << " x:" << xtmp << " x*invsqrt:" << t << " adding:" << t*xtmp << endl;
#else
#if defined(NORM_ADAPT_VAR)
	  t = xtmp*InvSqrt(sum_g*(sum_x2*timestep_inv));
#elif defined(NORM_ADAPT_VAR_NZ)
          timestep_inv = w[3];
          if(!all.normalized_adaptive_precompute) timestep_inv += 1.;
          timestep_inv = 1./timestep_inv;
          t = xtmp*InvSqrt(sum_g*(sum_x2*timestep_inv));
#elif defined(NORM_ADAPT_VAR_UB)
          range_max = w[3];
          if( fabs(xtmp) > range_max ) range_max = fabs(xtmp);
          t = xtmp*InvSqrt(sum_g*(sum_x2*timestep_inv + range_max*range_max*timestep_inv_sqrt));
#else
          t = xtmp*InvSqrt(sum_g);
#endif
#endif
#if defined(NORM_ADAPT_VAR) || defined(NORM_ADAPT_VAR_UB) || defined(NORM_ADAPT_VAR_NZ)
          xGNx += t * xtmp;
#elif defined(NORM_ADAPT_RANGE) || defined(NORM_ADAPT_ELLIPSE_APPROX)
          range_max = w[2];
          if( fabs(xtmp) > range_max ) range_max = fabs(xtmp);
          //if( range_max < 0.00001 ) cout << "tiny feature: index:" << (f->weight_index & mask) << " x:" << xtmp << " range_max:" << range_max << endl;
          xGNx += t * xtmp / range_max;
          norm_x += xtmp2 / (range_max*range_max);
#else
          range_max = w[2];
          range_min = w[3];
          if( xtmp > range_max ) range_max = xtmp;
          if( xtmp < range_min ) range_min = xtmp;	
          xGNx += t * xtmp / (range_max-range_min);
#endif

	}
    }
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    xGNx += xGNx_quad(all, weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, g, timestep_inv, norm_x);
	} 
    }

#ifdef NORM_ADAPT_ELLIPSE_APPROX
  if( (!all.normalized_adaptive_precompute || ec->pass > 0) && sqrt(norm_x) > all.normalized_adaptive_ellipse_max_norm_x)
    all.normalized_adaptive_ellipse_max_norm_x = sqrt(norm_x);
  xGNx /= all.normalized_adaptive_ellipse_max_norm_x;
#endif
  
  return xGNx;
}

void inline_train(vw& all, example* &ec, float update)
{
  if (fabs(update) == 0.)
    return;
  size_t mask = all.weight_mask;
  weight* weights = all.reg.weight_vectors;
  for (size_t* i = ec->indices.begin; i != ec->indices.end; i++) 
    {
      feature *f = ec->atomics[*i].begin;
      for (; f != ec->atomics[*i].end; f++){
	weights[f->weight_index & mask] += update * f->x;
      }
    }
  
  for (vector<string>::iterator i = all.pairs.begin(); i != all.pairs.end();i++) 
    {
      if (ec->atomics[(int)(*i)[0]].index() > 0)
	{
	  v_array<feature> temp = ec->atomics[(int)(*i)[0]];
	  for (; temp.begin != temp.end; temp.begin++)
	    one_pf_quad_update(weights, *temp.begin, ec->atomics[(int)(*i)[1]], mask, update);
	} 
    }
}

void train(weight* weights, const v_array<feature> &features, float update)
{
  if (fabs(update) > 0.)
    for (feature* j = features.begin; j != features.end; j++)
      weights[j->weight_index] += update * j->x;
}

void local_predict(vw& all, example* ec)
{
  label_data* ld = (label_data*)ec->ld;

  all.set_minmax(all.sd, ld->label);

  ec->final_prediction = finalize_prediction(all, ec->partial_prediction * all.sd->contraction);

  if(all.active_simulation){
    float k = ec->example_t - ld->weight;
    ec->revert_weight = all.loss->getRevertingWeight(all.sd, ec->final_prediction, all.eta/powf(k,all.power_t));
    float importance = query_decision(all, ec, k);
    if(importance > 0){
      all.sd->queries += 1;
      ld->weight *= importance;
    }
    else //do not query => do not train
      ld->label = FLT_MAX;
  }

  if( all.normalized_adaptive_precompute && ec->pass == 0) {
    ec->eta_round = 1.0;
    return;
  }

  float t;
  if(all.active)
    t = all.sd->weighted_unlabeled_examples;
  else
    t = ec->example_t;

  ec->eta_round = 0;
  if (ld->label != FLT_MAX)
    {
      ec->loss = all.loss->getLoss(all.sd, ec->final_prediction, ld->label) * ld->weight;
      if (all.training && ec->loss > 0.)
	{
	  double eta_t;
	  float norm;
          if(all.adaptive && all.norm_corr_adaptive ) {
            if (all.power_t == 0.5)
	      norm = compute_xGNCx(all, ec);
	    else 
	      norm = compute_general_xGNCx(all, ec, all.power_t);
	    eta_t = all.eta * norm * ld->weight;
            last_norm = norm;
            last_eta_t = eta_t;
            last_error = ld->label-ec->final_prediction;
          }
          if(all.adaptive && all.normalized_adaptive ) {
            if (all.power_t == 0.5)
	      norm = compute_xGNx(all, ec);
	    else 
	      norm = compute_general_xGNx(all, ec, all.power_t);
	    eta_t = all.eta * norm * ld->weight;
            last_norm = norm;
            last_eta_t = eta_t;
            last_error = ld->label-ec->final_prediction;
          }
	  else if (all.adaptive && all.exact_adaptive_norm) {
	    float magx = 0.;
	    if (all.power_t == 0.5)
	      norm = compute_xGx(all, ec);
	    else 
	      norm = compute_general_xGx(all, ec, all.power_t);
	    magx = powf(ec->total_sum_feat_sq, 1. - all.power_t);
	    eta_t = all.eta * norm / magx * ld->weight;
	  } else {
	    eta_t = all.eta / powf(t,all.power_t) * ld->weight;
	    if (all.nonormalize) 
	      {
		norm = 1.;
		eta_t *= ec->total_sum_feat_sq;
	      }
	    else
	      norm = ec->total_sum_feat_sq;
	  }
          float update = all.loss->getUpdate(ec->final_prediction, ld->label, eta_t, norm);
          last_update = update;
	  ec->eta_round = update / all.sd->contraction;

	  if (all.reg_mode && fabs(ec->eta_round) > 1e-8) {
	    double dev1 = all.loss->first_derivative(all.sd, ec->final_prediction, ld->label);
	    double eta_bar = (fabs(dev1) > 1e-8) ? (-ec->eta_round / dev1) : 0.0;
	    if (fabs(dev1) > 1e-8)
	      all.sd->contraction /= (1. + all.l2_lambda * eta_bar * norm);
	    all.sd->gravity += eta_bar * sqrt(norm) * all.l1_lambda;
	  }
	}
    }
  else if(all.active)
    ec->revert_weight = all.loss->getRevertingWeight(all.sd, ec->final_prediction, all.eta/powf(t,all.power_t));

  if (all.audit)
    print_audit_features(all, ec);

  print_update_status(t);
}

void predict(vw& all, example* ex)
{
  float prediction;
  if (all.reg_mode % 2)
    prediction = inline_predict_trunc(all, ex);
  else
    prediction = inline_predict(all, ex);

  ex->partial_prediction += prediction;

  local_predict(all, ex);
  ex->done = true;
}

void drive_gd(void* in)
{
  vw* all = (vw*)in;
  example* ec = NULL;
  
  while ( true )
    {
      if ((ec = get_example(all->p)) != NULL)//semiblocking operation.
	{
	  learn_gd(all, ec);
	  finish_example(*all, ec);
	}
      else if (parser_done(all->p))
	{
	  finish_gd(all);
	  return;
	}
      else 
	;//busywait when we have predicted on all examples but not yet trained on all.
    }
}
